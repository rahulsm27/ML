{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. INSTALL LIBRARIES AND PACKAGES","metadata":{}},{"cell_type":"code","source":"\n# Import the necessary libraries\n!pip install datasets\n!pip install transformers\n!pip install torch\n!pip install evaluate\n!pip install jiwer\n!pip install transformers[torch]\n!pip install numpy\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:48:27.836261Z","iopub.execute_input":"2023-11-26T07:48:27.837070Z","iopub.status.idle":"2023-11-26T07:49:55.599994Z","shell.execute_reply.started":"2023-11-26T07:48:27.837033Z","shell.execute_reply":"2023-11-26T07:49:55.598631Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: jiwer in /opt/conda/lib/python3.10/site-packages (3.0.3)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (3.5.2)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.24.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"##Imports required\nimport numpy as np\nfrom datasets import load_dataset, Audio, DatasetDict\nimport torch\nimport evaluate\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\nfrom transformers import Seq2SeqTrainingArguments,Seq2SeqTrainer\n#from transformers import TrainingArguments, Trainer\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:49:55.602709Z","iopub.execute_input":"2023-11-26T07:49:55.603153Z","iopub.status.idle":"2023-11-26T07:49:55.614668Z","shell.execute_reply.started":"2023-11-26T07:49:55.603102Z","shell.execute_reply":"2023-11-26T07:49:55.613363Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. IMPORT DATA","metadata":{}},{"cell_type":"code","source":"dataset = DatasetDict()\n\n# Load the PolyAI dataset.\n\ndataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train[:80]\")\n\n# Remove unnecessary columns\n\n\n# Split the datasedataset = dataset.remove_columns(['path','english_transcription','intent_class','lang_id'])\nt into train and test\ndataset = dataset.train_test_split(test_size = 0.2, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:50:30.575064Z","iopub.execute_input":"2023-11-26T07:50:30.576073Z","iopub.status.idle":"2023-11-26T07:50:31.104736Z","shell.execute_reply.started":"2023-11-26T07:50:30.576032Z","shell.execute_reply":"2023-11-26T07:50:31.103643Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"#dataset['train']['audio'][0]","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:50:41.030122Z","iopub.execute_input":"2023-11-26T07:50:41.030989Z","iopub.status.idle":"2023-11-26T07:50:41.036423Z","shell.execute_reply.started":"2023-11-26T07:50:41.030949Z","shell.execute_reply":"2023-11-26T07:50:41.035507Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"## Resample the dataset to 16 Khz as MCTCT model is trained on 16khz\ndataset['train'] = dataset['train'].cast_column(\"audio\", Audio(sampling_rate=16000))\ndataset['test'] = dataset['test'].cast_column(\"audio\", Audio(sampling_rate=16000))\n# #dataset['train'] = dataset['train'].rename_column(\"audio\", Audio(sampling_rate=16000))\n# dataset['train'] = dataset['train'].rename_column(\"transcription\",\"sentence\")\n# dataset['test'] = dataset['test'].rename_column(\"transcription\",\"sentence\")","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:50:41.329987Z","iopub.execute_input":"2023-11-26T07:50:41.330350Z","iopub.status.idle":"2023-11-26T07:50:41.348068Z","shell.execute_reply.started":"2023-11-26T07:50:41.330323Z","shell.execute_reply":"2023-11-26T07:50:41.347043Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:50:41.879344Z","iopub.execute_input":"2023-11-26T07:50:41.879756Z","iopub.status.idle":"2023-11-26T07:50:41.889009Z","shell.execute_reply.started":"2023-11-26T07:50:41.879727Z","shell.execute_reply":"2023-11-26T07:50:41.887872Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'sentence'],\n        num_rows: 64\n    })\n    test: Dataset({\n        features: ['audio', 'sentence'],\n        num_rows: 16\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3. DATA PREPROCESSING","metadata":{}},{"cell_type":"code","source":"from transformers import WhisperProcessor, WhisperForConditionalGeneration\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\",task=\"transcribe\", model_max_length=225)\nmodel = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny.en')\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T08:11:41.826511Z","iopub.execute_input":"2023-11-26T08:11:41.826929Z","iopub.status.idle":"2023-11-26T08:11:43.080808Z","shell.execute_reply.started":"2023-11-26T08:11:41.826893Z","shell.execute_reply":"2023-11-26T08:11:43.079451Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"# Preparing a function to process the entire dataset\n# We need to crate two variables with name 'input_featrues'(input array of sound wave in raw foram) and 'labels'(transcription)\n\ndef prepare_dataset(batch):\n    audio = batch[\"audio\"]\n\n   # batch[\"input_ids\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"],return_tensor = \"pt\").input_features[0]\n    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"],return_tensor = \"pt\").input_features[0]\n\n    #processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n  #  with processor.as_target_processor():\n    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n    return batch","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:50:44.011964Z","iopub.execute_input":"2023-11-26T07:50:44.012390Z","iopub.status.idle":"2023-11-26T07:50:44.021168Z","shell.execute_reply.started":"2023-11-26T07:50:44.012348Z","shell.execute_reply":"2023-11-26T07:50:44.020029Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"np.object = object    \nencoded_dataset = dataset.map(prepare_dataset, remove_columns=data.column_names[\"train\"],num_proc=4)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:58:50.147382Z","iopub.execute_input":"2023-11-26T07:58:50.148063Z","iopub.status.idle":"2023-11-26T07:58:57.907902Z","shell.execute_reply.started":"2023-11-26T07:58:50.148029Z","shell.execute_reply":"2023-11-26T07:58:57.906654Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/16 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b216250002d94a67ae7257304cbf161f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/16 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"901ea61856864dde82e5d005d465385c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/16 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"125d96c9818c47298b020d496f886cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/16 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0bffbcb716b4a7a8fa99af73a37763c"}},"metadata":{}},{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/4 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce7e3deda8c24beea6898b451d4edfaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/4 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e498c49df33f4127b45394117e4f1658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/4 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b47ea0f1bab14f6fb9f1b5a5b0965d39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/4 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed7f7f061ed146e1984054e026d6c879"}},"metadata":{}}]},{"cell_type":"code","source":"encoded_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-26T07:58:58.835626Z","iopub.execute_input":"2023-11-26T07:58:58.836024Z","iopub.status.idle":"2023-11-26T07:58:58.845439Z","shell.execute_reply.started":"2023-11-26T07:58:58.835986Z","shell.execute_reply":"2023-11-26T07:58:58.844394Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_features', 'labels'],\n        num_rows: 64\n    })\n    test: Dataset({\n        features: ['input_features', 'labels'],\n        num_rows: 16\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Creating a DataCollatorClass\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: processor\n    padding: Union[bool, str] = \"longest\"\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n#     def __call__(self, features):# List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need\n        # different padding methods\n       # print(features)\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        \n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n       # print(batch)\n        return batch #batch\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T08:22:42.793114Z","iopub.execute_input":"2023-11-26T08:22:42.794096Z","iopub.status.idle":"2023-11-26T08:22:42.809775Z","shell.execute_reply.started":"2023-11-26T08:22:42.794056Z","shell.execute_reply":"2023-11-26T08:22:42.808651Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T08:22:43.275696Z","iopub.execute_input":"2023-11-26T08:22:43.276585Z","iopub.status.idle":"2023-11-26T08:22:43.282265Z","shell.execute_reply.started":"2023-11-26T08:22:43.276544Z","shell.execute_reply":"2023-11-26T08:22:43.281214Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"\n# Evalution metric- We will be evaluating our model on word error rate\n\nwer = evaluate.load(\"wer\")\n\ndef compute_metrics(pred):\n    wer = evaluate.load(\"wer\")\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}\n\n# def compute_metrics(pred):\n#     wer = evaluate.load(\"wer\")\n#     pred_ids = pred.predictions\n#     label_ids = pred.label_ids\n\n#     # replace -100 with the pad_token_id\n#     label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n\n#     # we do not want to group tokens when computing the metrics\n#     pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n#     label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n#     wer = 100 * wer.compute(predictions=pred_str, references=label_str)\n\n#     return {\"wer\": wer}\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:20:26.103439Z","iopub.execute_input":"2023-11-26T09:20:26.104414Z","iopub.status.idle":"2023-11-26T09:20:26.573763Z","shell.execute_reply.started":"2023-11-26T09:20:26.104369Z","shell.execute_reply":"2023-11-26T09:20:26.572573Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"markdown","source":"#### 4. Training the model","metadata":{}},{"cell_type":"code","source":"# from transformers import WhisperForConditionalGeneration\n\n# model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n# model.config.forced_decoder_ids = None\n# model.config.suppress_tokens = []\n# defining training arguments and trainer\nmodel.config.forced_decoder_ids = None\nmodel.config.suppress_tokens = []\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"seqtoseq-trained\",\n    gradient_checkpointing=True,\n    per_device_train_batch_size=2,\n    learning_rate=1e-5,\n    warmup_steps=2,\n    max_steps=2000,\n    fp16=True ,#False ,#True,\n    optim='adafactor',\n   # group_by_length=True,\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=2,\n    eval_steps=100,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    report_to = [\"tensorboard\"],\n    #data_parallel=False\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"test\"],\n    tokenizer=processor,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    #data_parallel=False\n  #  sampler = None\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:20:27.578928Z","iopub.execute_input":"2023-11-26T09:20:27.579346Z","iopub.status.idle":"2023-11-26T09:20:27.602910Z","shell.execute_reply.started":"2023-11-26T09:20:27.579306Z","shell.execute_reply":"2023-11-26T09:20:27.601424Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"# for feature in encoded_dataset[\"train\"]:\n#     print (len(feature['input_ids']))\n#     print (len(feature['labels']))\n    \n#     break","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:20:28.262749Z","iopub.execute_input":"2023-11-26T09:20:28.263447Z","iopub.status.idle":"2023-11-26T09:20:28.268812Z","shell.execute_reply.started":"2023-11-26T09:20:28.263410Z","shell.execute_reply":"2023-11-26T09:20:28.267619Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Requires GPU for training\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:20:28.730690Z","iopub.execute_input":"2023-11-26T09:20:28.731580Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='619' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 619/2000 15:26 < 34:33, 0.67 it/s, Epoch 38.62/125]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>No log</td>\n      <td>0.449694</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>0.499984</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>No log</td>\n      <td>0.500583</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>No log</td>\n      <td>0.520113</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.000000</td>\n      <td>0.547275</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.000000</td>\n      <td>0.576372</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"## getting test data\ni2 = processor(dataset['test'][6][\"audio\"][\"array\"], sampling_rate=16000, return_tensors=\"pt\")\nprint(f\"The input test audio is: {dataset['test'][8]['transcription']}\")\n\n# prediction for test data\nwith torch.no_grad():\n    logits = model(**i2.to(device)).logits\n\npredicted_ids = torch.argmax(logits, dim=-1)\ntranscription = processor.batch_decode(predicted_ids)\nprint(f'The output prediction is : {transcription[0]}')\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}