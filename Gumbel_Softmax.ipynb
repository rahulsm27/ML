{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlJ23dnoTS/y/QmHYNx31/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulsm27/ML/blob/main/Gumbel_Softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V3ClWdc-3ywr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.distributions as D\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_gumbel(shape, eps=1e-20):\n",
        "    U = torch.rand(shape)\n",
        "    return -torch.log(-torch.log(U + eps) + eps)\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, temperature):\n",
        "    y = logits + sample_gumbel(logits.size())\n",
        "    return F.softmax(y / temperature, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, temperature, hard=False):\n",
        "    \"\"\"\n",
        "    ST-gumple-softmax\n",
        "    input: [*, n_class]\n",
        "    return: flatten --> [*, n_class] an one-hot vector\n",
        "    \"\"\"\n",
        "    y = gumbel_softmax_sample(logits, temperature)\n",
        "\n",
        "    if not hard:\n",
        "        return y.view(-1, latent_dim * 2)\n",
        "\n",
        "    shape = y.size()\n",
        "    _, ind = y.max(dim=-1)\n",
        "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
        "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
        "    y_hard = y_hard.view(*shape)\n",
        "    # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
        "    y_hard = (y_hard - y).detach() + y\n",
        "    return y_hard.view(-1, latent_dim * 2)"
      ],
      "metadata": {
        "id": "aKLEEWdb3zX7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "kvdBT8zc5Eux"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp=1\n",
        "latent_dim = 10\n",
        "gumbel_softmax(torch.rand(1, latent_dim*2), temp, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVDMG5zu6r76",
        "outputId": "b44bfe14-7349-4106-bc4c-930ae556d9b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0519, 0.0209, 0.0252, 0.0603, 0.0314, 0.2574, 0.0139, 0.0262, 0.0116,\n",
              "         0.0094, 0.0260, 0.0074, 0.0202, 0.0070, 0.0186, 0.3177, 0.0272, 0.0232,\n",
              "         0.0371, 0.0075]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gumbel_softmax(torch.rand(1, latent_dim*2), temp, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYBmV3yq5QBq",
        "outputId": "a424b5b5-e3ea-4e42-8533-c336f07b8ed8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYLWczHH5lXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}