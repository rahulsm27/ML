{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGU1Zou06uwgHJf1XWys5j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulsm27/ML/blob/main/Text_Generation_using_Fnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install libraries and import"
      ],
      "metadata": {
        "id": "INcbc_YTM0wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install torch[transformers]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gaqC--Vin3c",
        "outputId": "09c2b627-6cb8-463e-f7af-0dae6c46529b"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.5)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: torch[transformers] in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "\u001b[33mWARNING: torch 2.1.0+cu118 does not provide the extra 'transformers'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch[transformers]) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch[transformers]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch[transformers]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "z7BDQtHbgHwW"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "cpSgOyDnNCx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13e8904-1f93-4c29-9e08-fd0d7aa48205"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loading Data"
      ],
      "metadata": {
        "id": "TcbdKHGtM_PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "datasets = load_dataset('wikitext','wikitext-2-raw-v1')"
      ],
      "metadata": {
        "id": "8LurSU1rgSm0"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJtLNGM4imZ_",
        "outputId": "d51ad672-0b4e-4601-b162-1650d11de263"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 4358\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 36718\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3760\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYb5t2_jNLwf"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PREPROCESSING DATA"
      ],
      "metadata": {
        "id": "K-tqR-m_NHOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocess_text(sentence):\n",
        "  text = sentence['text'].lower() # lowering the sentence and storing in text vaiable\n",
        "  text = re.sub('[^a-z?!.,]',' ',text) # removing other than characters and punctuations\n",
        "  text = re.sub('\\s\\s+',' ',text) # removing double spaces\n",
        "  sentence['text'] = text\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "nJQfm0zki0ia"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['train'] = datasets['train'].map(preprocess_text)\n",
        "datasets['test'] = datasets['test'].map(preprocess_text)\n",
        "datasets['validation'] = datasets['validation'].map(preprocess_text)"
      ],
      "metadata": {
        "id": "LaLayNePv61c"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['train'] = datasets['train'].filter(lambda x : len(x['text']) > 20)\n",
        "datasets['test'] = datasets['test'].filter(lambda x : len(x['text']) > 20)\n",
        "datasets['validation'] = datasets['validation'].filter(lambda x : len(x['text']) > 20)"
      ],
      "metadata": {
        "id": "szzyfA19xspG"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets"
      ],
      "metadata": {
        "id": "btKuKpLbwJPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a963245-9cb7-4fb0-9226-cb60b3279633"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 2312\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 18794\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 1988\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLTW7ssTNN0N"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. TOKENIZATION"
      ],
      "metadata": {
        "id": "zAKj9639NOYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "eUmPYWBrF90F"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnV3SRtGvBu",
        "outputId": "4a937da2-3d3e-48c5-b80f-a70423dde9fb"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'unk_token': '[UNK]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "kaPsscckHdoV"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "  sentence = tokenizer(sentence['text'],truncation = True)\n",
        "\n",
        "  return sentence\n",
        "\n",
        "tokenized_inputs = datasets['train'].map(tokenize)"
      ],
      "metadata": {
        "id": "NCGtPcGHNUuo"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_inputs = tokenized_inputs.remove_columns(['text','token_type_ids'])"
      ],
      "metadata": {
        "id": "_-wviCing1Ry"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch = 16\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors =\"pt\")\n",
        "dataloader = DataLoader(tokenized_inputs,batch_size=batch,collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "vKU0UAt4IbbK"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nnqZXxeveuUf"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataloader)\n"
      ],
      "metadata": {
        "id": "X59bp2pRPhlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad45d20-9ec2-48ff-a881-94c563e3f2fe"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. MODEL"
      ],
      "metadata": {
        "id": "3T-vgP77M_Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.fft as fft\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SUgR3zHjPueb"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module that creates a positional encoding matrix. This matrix will later be added to the\n",
        "    transformer's input embeddings to provide a sense of position of the sequence elements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.positional_encoding = self.create_positional_encoding()\n",
        "\n",
        "    def create_positional_encoding(self):\n",
        "        \"\"\"\n",
        "        Creates a positional encoding matrix of size (max_sequence_length, d_model).\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize positional encoding matrix\n",
        "        positional_encoding = np.zeros((self.max_sequence_length, self.d_model))\n",
        "\n",
        "        # Calculate positional encoding for each position and each dimension\n",
        "        for pos in range(self.max_sequence_length):\n",
        "            for i in range(0, self.d_model, 2):\n",
        "                # Apply sin to even indices in the array; indices in Python start at 0 so i is even.\n",
        "                positional_encoding[pos, i] = np.sin(pos / (10000 ** ((2 * i) / self.d_model)))\n",
        "\n",
        "                if i + 1 < self.d_model:\n",
        "                    # Apply cos to odd indices in the array; we add 1 to i because indices in Python start at 0.\n",
        "                    positional_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((2 * i) / self.d_model)))\n",
        "\n",
        "        # Convert numpy array to PyTorch tensor and return it\n",
        "        return torch.from_numpy(positional_encoding).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Adds the positional encoding to the input embeddings at the corresponding positions.\n",
        "        \"\"\"\n",
        "        # Add positional encodings to input embeddings. The \":\" indexing ensures we only add positional encodings up\n",
        "        # to the length of the sequence in the batch. x.size(0) is the batch size, so this is a way to make sure\n",
        "        # we're not adding extra positional encodings.\n",
        "        expanded_tensor = torch.unsqueeze(self.positional_encoding, 0).expand(x.size(0), -1, -1)\n",
        "\n",
        "        return x + expanded_tensor[:,:x.size(1), :]\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim):\n",
        "    super(PositionalEmbedding, self).__init__()\n",
        "    self.token_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.position_embeddings = PositionalEncoding(embed_dim,sequence_length)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions = self.position_embeddings(embedded_tokens)\n",
        "    return embedded_positions\n"
      ],
      "metadata": {
        "id": "a7t8ItlYZLGS"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qmntCODqWU_"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGPZ-svXqWQU"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNetEncoder(nn.Module):\n",
        "\n",
        "  def __init__(self,embed_dim, dense_dim):\n",
        "    super(FNetEncoder,self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dense_dim = dense_dim\n",
        "    self.dense_proj = nn.Sequential(nn.Linear(self.embed_dim,self.dense_dim), nn.ReLU(), nn.Linear(self.dense_dim,self.embed_dim))\n",
        "\n",
        "    self.layernorm_1 = nn.LayerNorm(self.embed_dim)\n",
        "    self.layernorm_2 = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "\n",
        "    fft_result = fft.fft2(inputs)\n",
        "\n",
        "    #taking real part\n",
        "    fft_real = fft_result.real.float()\n",
        "\n",
        "    proj_input = self.layernorm_1 (inputs + fft_real)\n",
        "    proj_output = self.dense_proj(proj_input)\n",
        "    return self.layernorm_2(proj_input +proj_output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V6j0leewQwUz"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNetDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self,embed_dim,dense_dim,num_heads):\n",
        "    super(FNetDecoder,self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dense_dim = dense_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.attention_1 = nn.MultiheadAttention(embed_dim,num_heads)\n",
        "    self.attention_2 = nn.MultiheadAttention(embed_dim,num_heads)\n",
        "\n",
        "    self.dense_proj = nn.Sequential(nn.Linear(embed_dim, latent_dim),nn.ReLU(),nn.Linear(latent_dim, embed_dim))\n",
        "\n",
        "    self.layernorm_1 = nn.LayerNorm(embed_dim)\n",
        "    self.layernorm_2 = nn.LayerNorm(embed_dim)\n",
        "    self.layernorm_3 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "  def forward(self, inputs, encoder_outputs, mask=None):\n",
        "    causal_mask = nn.Transformer.generate_square_subsequent_mask(inputs.size(0)).to(device)\n",
        "\n",
        "    if mask is not None:\n",
        "        padding_mask = mask.unsqueeze(1)\n",
        "        padding_mask = torch.min(padding_mask, causal_mask)\n",
        "\n",
        "    attention_output_1, _ = self.attention_1(inputs, inputs, inputs, attn_mask=causal_mask)\n",
        "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    print(inputs.size(),out_1.size(),encoder_outputs.size())\n",
        "\n",
        "    attention_output_2, _ = self.attention_2(out_1, encoder_outputs, encoder_outputs, attn_mask=causal_mask)\n",
        "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "    proj_output = self.dense_proj(out_2)\n",
        "    return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "TOTs8hpri1MI"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNetModel(nn.Module):\n",
        "    def __init__(self, max_length, vocab_size, embed_dim, latent_dim, num_heads):\n",
        "        super(FNetModel, self).__init__()\n",
        "\n",
        "        self.encoder_inputs = PositionalEmbedding(max_length,vocab_size, embed_dim)\n",
        "        self.encoder = FNetEncoder(embed_dim, latent_dim)\n",
        "\n",
        "        self.decoder_inputs = PositionalEmbedding(max_length,vocab_size, embed_dim)\n",
        "   #     self.decoder_state_inputs = nn.Linear(embed_dim, latent_dim)\n",
        "        self.decoder = FNetDecoder(embed_dim, latent_dim, num_heads)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.dense = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_inputs, decoder_inputs):\n",
        "        x_encoder = self.encoder_inputs(encoder_inputs)\n",
        "        x_encoder = self.encoder(x_encoder)\n",
        "        print(decoder_inputs.size())\n",
        "        x_decoder = self.decoder_inputs(decoder_inputs)\n",
        "     #   print(x_decoder.size())\n",
        "      #  x_decoder_state = self.decoder_state_inputs(x_encoder[:, -1, :])\n",
        "     #   print(x_decoder_state.size())\n",
        "\n",
        "        x_decoder = self.decoder(x_decoder[:,:,:], x_encoder[:,:,:])\n",
        "        x_decoder = self.dropout(x_decoder)\n",
        "  #      print(x_decoder.size())\n",
        "\n",
        "        decoder_outputs = self.dense(x_decoder)\n",
        "        return F.softmax(decoder_outputs, dim=-1)"
      ],
      "metadata": {
        "id": "g87BEd1QZNzM"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your constants are defined like this:\n",
        "MAX_LENGTH = 512\n",
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMBED_DIM = 256\n",
        "LATENT_DIM = 100\n",
        "NUM_HEADS = 4\n",
        "\n",
        "# Create an instance of the model\n",
        "fnet_model = FNetModel(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM, LATENT_DIM, NUM_HEADS)\n",
        "\n",
        "# # Define your optimizer and loss function\n",
        "optimizer = torch.optim.Adam(fnet_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # Convert your data to PyTorch tensors\n",
        "# # Example:\n",
        "# # encoder_inputs_tensor = torch.tensor(encoder_inputs_data)\n",
        "# # decoder_inputs_tensor = torch.tensor(decoder_inputs_data)\n",
        "# # target_tensor = torch.tensor(target_data)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  for batch in dataloader:\n",
        "    encoder_inputs_tensor = torch.tensor(batch['input_ids'][:,:-1])\n",
        "    decoder_inputs_tensor = torch.tensor(batch['input_ids'][:,1:])\n",
        "    optimizer.zero_grad()\n",
        "    outputs = fnet_model(encoder_inputs_tensor, decoder_inputs_tensor)\n",
        "    loss = criterion(outputs.view(-1, VOCAB_SIZE), decoder_inputs_tensor.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aQ9-rZ4pZNxY",
        "outputId": "20ea648c-3c7c-4e78-c802-a6f803308f32"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-353-1bdb5ab3dafd>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoder_inputs_tensor = torch.tensor(batch['input_ids'][:,:-1])\n",
            "<ipython-input-353-1bdb5ab3dafd>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  decoder_inputs_tensor = torch.tensor(batch['input_ids'][:,1:])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 329])\n",
            "torch.Size([16, 329, 256]) torch.Size([16, 329, 256]) torch.Size([16, 329, 256])\n",
            "torch.Size([16, 285])\n",
            "torch.Size([16, 285, 256]) torch.Size([16, 285, 256]) torch.Size([16, 285, 256])\n",
            "torch.Size([16, 179])\n",
            "torch.Size([16, 179, 256]) torch.Size([16, 179, 256]) torch.Size([16, 179, 256])\n",
            "torch.Size([16, 209])\n",
            "torch.Size([16, 209, 256]) torch.Size([16, 209, 256]) torch.Size([16, 209, 256])\n",
            "torch.Size([16, 178])\n",
            "torch.Size([16, 178, 256]) torch.Size([16, 178, 256]) torch.Size([16, 178, 256])\n",
            "torch.Size([16, 188])\n",
            "torch.Size([16, 188, 256]) torch.Size([16, 188, 256]) torch.Size([16, 188, 256])\n",
            "torch.Size([16, 222])\n",
            "torch.Size([16, 222, 256]) torch.Size([16, 222, 256]) torch.Size([16, 222, 256])\n",
            "torch.Size([16, 17])\n",
            "torch.Size([16, 17, 256]) torch.Size([16, 17, 256]) torch.Size([16, 17, 256])\n",
            "torch.Size([16, 14])\n",
            "torch.Size([16, 14, 256]) torch.Size([16, 14, 256]) torch.Size([16, 14, 256])\n",
            "torch.Size([16, 18])\n",
            "torch.Size([16, 18, 256]) torch.Size([16, 18, 256]) torch.Size([16, 18, 256])\n",
            "torch.Size([16, 188])\n",
            "torch.Size([16, 188, 256]) torch.Size([16, 188, 256]) torch.Size([16, 188, 256])\n",
            "torch.Size([16, 186])\n",
            "torch.Size([16, 186, 256]) torch.Size([16, 186, 256]) torch.Size([16, 186, 256])\n",
            "torch.Size([16, 390])\n",
            "torch.Size([16, 390, 256]) torch.Size([16, 390, 256]) torch.Size([16, 390, 256])\n",
            "torch.Size([16, 238])\n",
            "torch.Size([16, 238, 256]) torch.Size([16, 238, 256]) torch.Size([16, 238, 256])\n",
            "torch.Size([16, 338])\n",
            "torch.Size([16, 338, 256]) torch.Size([16, 338, 256]) torch.Size([16, 338, 256])\n",
            "torch.Size([16, 302])\n",
            "torch.Size([16, 302, 256]) torch.Size([16, 302, 256]) torch.Size([16, 302, 256])\n",
            "torch.Size([16, 407])\n",
            "torch.Size([16, 407, 256]) torch.Size([16, 407, 256]) torch.Size([16, 407, 256])\n",
            "torch.Size([16, 213])\n",
            "torch.Size([16, 213, 256]) torch.Size([16, 213, 256]) torch.Size([16, 213, 256])\n",
            "torch.Size([16, 163])\n",
            "torch.Size([16, 163, 256]) torch.Size([16, 163, 256]) torch.Size([16, 163, 256])\n",
            "torch.Size([16, 306])\n",
            "torch.Size([16, 306, 256]) torch.Size([16, 306, 256]) torch.Size([16, 306, 256])\n",
            "torch.Size([16, 307])\n",
            "torch.Size([16, 307, 256]) torch.Size([16, 307, 256]) torch.Size([16, 307, 256])\n",
            "torch.Size([16, 268])\n",
            "torch.Size([16, 268, 256]) torch.Size([16, 268, 256]) torch.Size([16, 268, 256])\n",
            "torch.Size([16, 325])\n",
            "torch.Size([16, 325, 256]) torch.Size([16, 325, 256]) torch.Size([16, 325, 256])\n",
            "torch.Size([16, 295])\n",
            "torch.Size([16, 295, 256]) torch.Size([16, 295, 256]) torch.Size([16, 295, 256])\n",
            "torch.Size([16, 299])\n",
            "torch.Size([16, 299, 256]) torch.Size([16, 299, 256]) torch.Size([16, 299, 256])\n",
            "torch.Size([16, 320])\n",
            "torch.Size([16, 320, 256]) torch.Size([16, 320, 256]) torch.Size([16, 320, 256])\n",
            "torch.Size([16, 290])\n",
            "torch.Size([16, 290, 256]) torch.Size([16, 290, 256]) torch.Size([16, 290, 256])\n",
            "torch.Size([16, 242])\n",
            "torch.Size([16, 242, 256]) torch.Size([16, 242, 256]) torch.Size([16, 242, 256])\n",
            "torch.Size([16, 278])\n",
            "torch.Size([16, 278, 256]) torch.Size([16, 278, 256]) torch.Size([16, 278, 256])\n",
            "torch.Size([16, 351])\n",
            "torch.Size([16, 351, 256]) torch.Size([16, 351, 256]) torch.Size([16, 351, 256])\n",
            "torch.Size([16, 265])\n",
            "torch.Size([16, 265, 256]) torch.Size([16, 265, 256]) torch.Size([16, 265, 256])\n",
            "torch.Size([16, 338])\n",
            "torch.Size([16, 338, 256]) torch.Size([16, 338, 256]) torch.Size([16, 338, 256])\n",
            "torch.Size([16, 270])\n",
            "torch.Size([16, 270, 256]) torch.Size([16, 270, 256]) torch.Size([16, 270, 256])\n",
            "torch.Size([16, 114])\n",
            "torch.Size([16, 114, 256]) torch.Size([16, 114, 256]) torch.Size([16, 114, 256])\n",
            "torch.Size([16, 161])\n",
            "torch.Size([16, 161, 256]) torch.Size([16, 161, 256]) torch.Size([16, 161, 256])\n",
            "torch.Size([16, 279])\n",
            "torch.Size([16, 279, 256]) torch.Size([16, 279, 256]) torch.Size([16, 279, 256])\n",
            "torch.Size([16, 277])\n",
            "torch.Size([16, 277, 256]) torch.Size([16, 277, 256]) torch.Size([16, 277, 256])\n",
            "torch.Size([16, 206])\n",
            "torch.Size([16, 206, 256]) torch.Size([16, 206, 256]) torch.Size([16, 206, 256])\n",
            "torch.Size([16, 424])\n",
            "torch.Size([16, 424, 256]) torch.Size([16, 424, 256]) torch.Size([16, 424, 256])\n",
            "torch.Size([16, 244])\n",
            "torch.Size([16, 244, 256]) torch.Size([16, 244, 256]) torch.Size([16, 244, 256])\n",
            "torch.Size([16, 434])\n",
            "torch.Size([16, 434, 256]) torch.Size([16, 434, 256]) torch.Size([16, 434, 256])\n",
            "torch.Size([16, 348])\n",
            "torch.Size([16, 348, 256]) torch.Size([16, 348, 256]) torch.Size([16, 348, 256])\n",
            "torch.Size([16, 280])\n",
            "torch.Size([16, 280, 256]) torch.Size([16, 280, 256]) torch.Size([16, 280, 256])\n",
            "torch.Size([16, 511])\n",
            "torch.Size([16, 511, 256]) torch.Size([16, 511, 256]) torch.Size([16, 511, 256])\n",
            "torch.Size([16, 143])\n",
            "torch.Size([16, 143, 256]) torch.Size([16, 143, 256]) torch.Size([16, 143, 256])\n",
            "torch.Size([16, 189])\n",
            "torch.Size([16, 189, 256]) torch.Size([16, 189, 256]) torch.Size([16, 189, 256])\n",
            "torch.Size([16, 376])\n",
            "torch.Size([16, 376, 256]) torch.Size([16, 376, 256]) torch.Size([16, 376, 256])\n",
            "torch.Size([16, 353])\n",
            "torch.Size([16, 353, 256]) torch.Size([16, 353, 256]) torch.Size([16, 353, 256])\n",
            "torch.Size([16, 214])\n",
            "torch.Size([16, 214, 256]) torch.Size([16, 214, 256]) torch.Size([16, 214, 256])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-353-1bdb5ab3dafd>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#VOCAB = vectorizer.get_vocabulary()\n",
        "MAX_LENGTH =10 # your MAX_LENGTH value\n",
        "\n",
        "def decode_sentence(input_sentence, fnet_model):\n",
        "    # Mapping the input sentence to tokens and adding start and end tokens\n",
        "    tokenized_input_sentence = torch.tensor(tokenizer(\"[start] \" + preprocess_text(input_sentence)['text'] + \" [end]\")['input_ids'])# )\n",
        "     # Initializing the initial sentence consisting of only the start token.\n",
        "    tokenized_target_sentence = torch.tensor([1,2,3])\n",
        " #   print(tokenized_target_sentence.size())\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            predictions = fnet_model(\n",
        "                tokenized_input_sentence.unsqueeze(0),\n",
        "                tokenized_target_sentence.unsqueeze(0),\n",
        "            )\n",
        "        # Calculating the token with maximum probability and getting the corresponding word\n",
        "        sampled_token_index = torch.argmax(predictions[0, 0, :]).item()\n",
        " #       sampled_token = tokenizer.vocab[sampled_token_index]\n",
        "        # If sampled token is the end token then stop generating and return the sentence\n",
        "      #  if sampled_token == \"[end]\":\n",
        "       #     break\n",
        "        decoded_sentence += str(sampled_token_index) + \" \"\n",
        "        tokenized_target_sentence = torch.cat(\n",
        "            [tokenized_target_sentence, torch.tensor([sampled_token_index])], 0\n",
        "        )\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Assuming you have a PyTorch model named fnet_model\n",
        "# You need to pass fnet_model as an argument to the function\n",
        "#decode fnet_model = YourPyTorchModel()\n",
        "decode_sentence({'text':'Where have  you all been all this time?'}, fnet_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "DTCwvvWGZNuc",
        "outputId": "b80825c1-8f1c-4f0d-8dbf-50d8cc326d0a"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([1, 3, 256]) torch.Size([1, 3, 256]) torch.Size([1, 17, 256])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-354-e2c04c9c2e41>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# You need to pass fnet_model as an argument to the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#decode fnet_model = YourPyTorchModel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdecode_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Where have  you all been all this time?'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnet_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-354-e2c04c9c2e41>\u001b[0m in \u001b[0;36mdecode_sentence\u001b[0;34m(input_sentence, fnet_model)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Get the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             predictions = fnet_model(\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mtokenized_input_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mtokenized_target_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-352-37b0c74b9a45>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_inputs, decoder_inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m      \u001b[0;31m#   print(x_decoder_state.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m#      print(x_decoder.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-312-199f893b935e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_outputs, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mattention_output_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mout_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_output_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5344\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatic_k\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5346\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5348\u001b[0m         \u001b[0;31m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 12, 64]' is invalid for input of size 4352"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGIcLS9CsMYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_h5JKVvsMVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOIViVxmsMSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5kOLfHNZNXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vNOXdPZfZNU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbtJcztOZNSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8n4kHiUeZNPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9pA2PyG1ZNNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pb0LjSGIZNKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class FNetTextGenerator(nn.Module):\n",
        "  def __init__(self, embed_dim, latent_dim, vocab_size, max_seq_len, num_heads):\n",
        "    super(FNetTextGenerator, self).__init__()\n",
        "    self.positional = PositionalEmbedding(max_seq_len, vocab_size, embed_dim)\n",
        "    self.encoder = FNetEncoder(embed_dim,latent_dim)\n",
        "    self.decoder = FNetDecoder(embed_dim, latent_dim, num_heads)\n",
        "\n",
        "  def forward(self, inputs, target=None):\n",
        "    positional_inputs = self.positional(inputs)\n",
        "    encoder_output = self.encoder(positional_inputs)\n",
        "#    print(encoder_output.size())\n",
        "    if target is not None:\n",
        "      decoder_output = self.decoder(target, encoder_output)\n",
        "      return decoder_output\n",
        "\n",
        "    # If no target is provided, generate autoregressively\n",
        "    batch_size, seq_len = inputs.size()\n",
        "  #  print(inputs.size())\n",
        "    generated_sequence = torch.zeros(batch_size, seq_len, dtype=torch.long, device=inputs.device)\n",
        "\n",
        "        # Initial input for autoregressive decoding\n",
        "    input_token = inputs[:, 0].unsqueeze(1).float()\n",
        " #   print(input_token)\n",
        "\n",
        "# ...\n",
        "\n",
        "    for t in range(1, seq_len):\n",
        "      decoder_output = self.decoder(positional_inputs, encoder_output)\n",
        "\n",
        "    # Use torch.argmax directly to get the indices of the maximum values\n",
        "      predicted_token = torch.argmax(F.softmax(decoder_output, dim=-1), dim=-1)\n",
        "\n",
        "          # Check the shape of predicted_token before updating the generated sequence\n",
        "      print(f\"Shape of predicted_token before update: {predicted_token.shape}\")\n",
        "\n",
        "\n",
        "    # Ensure that predicted_token has the correct shape\n",
        "      predicted_token = predicted_token.unsqueeze(1)\n",
        "\n",
        "    # Update the generated sequence\n",
        "      generated_sequence[:, t] = predicted_token.squeeze()\n",
        "\n",
        "    # Update input_token for the next iteration\n",
        "      input_token = predicted_token\n",
        "\n",
        "\n",
        "\n",
        "    return generated_sequence\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 256\n",
        "latent_dim = 512\n",
        "vocab_size = 10000\n",
        "max_seq_len = 50\n",
        "num_heads = 8\n",
        "\n",
        "\n",
        "\n",
        "model = FNetTextGenerator(embed_dim, latent_dim, vocab_size, max_seq_len, num_heads).to(device)\n",
        "\n",
        "# Dummy input\n",
        "inputs = torch.randint(0, vocab_size, (16, max_seq_len)).long().to(device)\n",
        "\n",
        "\n",
        "# Forward pass for text generation\n",
        "generated_sequence = model(inputs)\n",
        "print(\"Generated Sequence:\", generated_sequence)"
      ],
      "metadata": {
        "id": "6CJl9jzMi1HA",
        "outputId": "5a37f27a-dc34-4eb4-f697-3405591ab7b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of predicted_token before update: torch.Size([16, 50])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2b3728802bf9>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Forward pass for text generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated Sequence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2b3728802bf9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, target)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Update the generated sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Update input_token for the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.LongTensor{[16, 50]}, size=[16]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YEf_9tgG6UuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6L9MfZl3i1ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randint(0, vocab_size, (16, max_seq_len)).to(device)"
      ],
      "metadata": {
        "id": "N4cWLfC7i1Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.dtype"
      ],
      "metadata": {
        "id": "ESzOG_3Vi0_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIPaRAr4i08m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHtD0MZvi06F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H7unSim_i03p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMOlDWTNi00o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNetTextGenerator(nn.Module):\n",
        "    def __init__(self, embed_dim, latent_dim, vocab_size, max_seq_len, num_heads, num_layers):\n",
        "        super(FNetTextGenerator, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
        "        self.transformer_decoder_layer = nn.TransformerDecoderLayer(embed_dim, num_heads)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(self.transformer_decoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.transformer_encoder_layer = FNetEncoder(embed_dim, latent_dim)\n",
        "      #  self.transformer_encoder = torch.nn.TransformerEncoder(self.transformer_encoder_layer, num_layers = num_layers)\n",
        "\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, target=None):\n",
        "        seq_length = inputs.size(1)\n",
        "\n",
        "        embedded_tokens = self.embedding(inputs)\n",
        "        positions = torch.arange(0, seq_length, device=inputs.device).unsqueeze(0)\n",
        "        embedded_positions = self.positional_embedding(positions)\n",
        "        encoder_input = embedded_tokens + embedded_positions\n",
        "\n",
        "        encoder_output = self.transformer_encoder_layer(encoder_input)\n",
        "\n",
        "        if target is not None:\n",
        "            target = target.permute(1, 0, 2)  # Adjust the shape for transformer decoder\n",
        "            decoder_output = self.transformer_decoder(target, encoder_output)\n",
        "            return decoder_output.permute(1, 0, 2)  # Adjust the shape back to batch-first\n",
        "\n",
        "        # If no target is provided, generate autoregressively\n",
        "        batch_size, seq_len = inputs.size()\n",
        "        generated_sequence = torch.zeros(batch_size, seq_len, dtype=torch.long, device=inputs.device)\n",
        "\n",
        "        # Initial input for autoregressive decoding\n",
        "        input_token = inputs[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, seq_len):\n",
        "            embedded_input_token = self.embedding(input_token) + self.positional_embedding(torch.tensor([[t]]).to(inputs.device))\n",
        "            decoder_output = self.transformer_decoder(embedded_input_token, encoder_output)\n",
        "            logits = self.fc(decoder_output[-1])\n",
        "            _, predicted_token = torch.max(F.softmax(logits, dim=-1), dim=-1)\n",
        "            generated_sequence[:, t] = predicted_token.squeeze()\n",
        "\n",
        "            input_token = predicted_token.unsqueeze(1)\n",
        "\n",
        "        return generated_sequence\n",
        "\n"
      ],
      "metadata": {
        "id": "kbyGefdHazVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "embed_dim = 256\n",
        "latent_dim = 512\n",
        "vocab_size = 10000\n",
        "max_seq_len = 50\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "\n",
        "model = FNetTextGenerator(embed_dim, latent_dim, vocab_size, max_seq_len, num_heads, num_layers).to(device)\n",
        "\n",
        "# Dummy input\n",
        "inputs = torch.randint(0, vocab_size, (2, max_seq_len)).to(device)\n",
        "\n",
        "# Forward pass for text generation\n",
        "generated_sequence = model(inputs)\n",
        "print(\"Generated Sequence:\", generated_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "Ym3LMVT1cekA",
        "outputId": "3a1079e2-541b-4427-bc68-1770a57d73fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-606cc94ec858>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFNetTextGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Dummy input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FNetTextGenerator.__init__() takes 6 positional arguments but 7 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIEJYOfRcfTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3fd1f9b8-fe44-48be-cb42-2993839157ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fe974e565db0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY9x76ind0qD",
        "outputId": "8a90a015-9931-43f3-de9b-fb7ab3d47e20"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4M6xFK8Vn2lT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}