{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8Yg1h5XhxtEfNogua62hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulsm27/ML/blob/main/Newton_Method_for_Neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzfDHOW9ID9I",
        "outputId": "39239655-6eb6-4325-81da-acd7bf60fab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# Installing required libraries\n",
        "!pip install torchinfo\n",
        "import torchinfo\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device = \"cpu\""
      ],
      "metadata": {
        "id": "V6P_7CeWIGlz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our own LeNet5\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5) # in channel , out channe, kernel\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.maxpool1 = nn.MaxPool2d((2,2))\n",
        "\n",
        "    self.conv2 = nn.Conv2d(6,16,5)  # in channel , out channe, kernel\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.maxpool2 = nn.MaxPool2d((2,2))\n",
        "\n",
        "    self.fc1 = nn.Linear(16*5*5,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    x = self.relu1(x)\n",
        "    x= self.maxpool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu2(x)\n",
        "    x= self.maxpool2(x)\n",
        "\n",
        "    x = x.view(-1,int(x.nelement() / x.shape[0]))\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "model = LeNet5().to(device)\n",
        "torch.nn.init.xavier_uniform_(model.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(model.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(model.fc1.weight)\n",
        "torch.nn.init.xavier_uniform_(model.fc2.weight)\n",
        "torch.nn.init.xavier_uniform_(model.fc3.weight)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM9gGCNQIODF",
        "outputId": "5e23b90f-c556-4926-da29-9b1c54df27f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.0485e-01,  2.6221e-02,  1.4305e-01,  1.1258e-01,  2.5070e-01,\n",
              "         -1.0132e-01,  6.2419e-02, -2.3740e-01,  1.6299e-01, -1.3893e-01,\n",
              "         -1.8354e-01,  2.0188e-01,  1.1389e-01, -1.1026e-01,  1.3351e-02,\n",
              "         -7.2104e-02, -1.5396e-01, -4.9009e-02,  1.7185e-01, -1.3751e-01,\n",
              "          6.3576e-02, -9.5254e-02, -1.9802e-01, -1.7262e-01,  1.0346e-01,\n",
              "         -1.4084e-01, -1.1738e-01,  5.1683e-02,  1.4973e-01,  7.8608e-02,\n",
              "          9.5203e-02,  1.8488e-01, -8.1277e-02,  1.0353e-01,  9.4987e-02,\n",
              "         -1.1507e-01,  1.5491e-01, -1.8417e-01, -6.1050e-02,  2.4740e-01,\n",
              "         -2.0524e-01, -1.3729e-01, -7.1980e-03, -1.1359e-01,  1.6201e-01,\n",
              "          1.5694e-01,  1.7936e-01, -1.2450e-01, -8.3718e-02,  1.4556e-01,\n",
              "          1.6879e-01, -1.7526e-01,  2.3363e-01,  2.3453e-01,  1.4639e-01,\n",
              "          2.0151e-01, -1.2142e-02,  6.9319e-02,  8.4938e-02,  2.2199e-02,\n",
              "         -1.6115e-01, -5.9874e-02,  9.5377e-02,  8.9639e-02, -1.1257e-02,\n",
              "          1.8728e-01,  2.1776e-01, -2.3566e-01, -6.8368e-02,  7.0483e-02,\n",
              "          1.3240e-01, -1.6981e-01, -2.0979e-01,  6.9862e-02, -2.4234e-01,\n",
              "         -2.3753e-01, -9.2940e-02,  2.5199e-01, -1.4845e-01,  1.7351e-01,\n",
              "         -1.6568e-01, -1.1267e-01,  5.4056e-02,  1.8369e-01],\n",
              "        [-4.5821e-03,  1.1007e-01,  1.3698e-01, -1.0349e-01,  3.0950e-02,\n",
              "         -1.6883e-01,  2.9080e-02,  7.1735e-02,  1.7494e-01, -3.9947e-02,\n",
              "         -1.0193e-01, -1.9548e-01,  2.2627e-01, -1.3481e-01, -1.2607e-01,\n",
              "          1.6009e-01,  6.3530e-02, -2.0251e-01,  2.1173e-01, -1.8254e-01,\n",
              "         -2.1434e-03,  5.1337e-03, -6.4037e-02, -1.8419e-01, -9.4039e-02,\n",
              "         -1.1470e-01, -1.9015e-02, -2.0433e-01, -2.2635e-01,  9.6244e-02,\n",
              "          1.0485e-01,  2.1690e-01, -8.1453e-02, -1.2189e-01,  1.7955e-01,\n",
              "          3.7644e-02,  1.6624e-01, -1.9524e-01,  1.3957e-01,  1.6486e-03,\n",
              "         -1.7653e-01,  2.5264e-01,  3.8466e-02,  1.0953e-01, -5.5335e-02,\n",
              "         -2.3688e-01, -1.4793e-01, -3.4657e-02, -4.2962e-03, -1.2801e-01,\n",
              "          1.8677e-01,  1.4475e-01, -2.1527e-01, -1.8771e-01,  8.6397e-02,\n",
              "         -5.0538e-02,  2.2901e-01,  6.9363e-02,  2.4234e-01,  8.6754e-02,\n",
              "         -1.5070e-01, -2.1579e-01, -1.7138e-01,  2.4717e-01, -4.1680e-02,\n",
              "          2.1059e-01,  3.3365e-02, -1.7490e-02, -1.1062e-01,  1.0162e-01,\n",
              "         -7.2125e-02, -2.8111e-02,  2.2037e-01,  1.0674e-01,  1.8112e-01,\n",
              "         -1.5404e-01, -1.6503e-01, -4.8134e-02,  6.2739e-02,  1.8130e-01,\n",
              "         -1.8170e-01,  1.5510e-01,  2.1352e-01,  7.5957e-02],\n",
              "        [ 2.2476e-01, -2.2338e-01,  1.4406e-02,  1.9284e-01,  2.4653e-01,\n",
              "         -6.4907e-02, -2.5980e-02, -1.3133e-01, -3.2998e-02,  1.0669e-02,\n",
              "         -4.0022e-02,  2.3391e-02,  2.3394e-01, -1.6140e-02,  1.0399e-01,\n",
              "          9.9333e-02, -8.6928e-02,  2.2076e-01, -2.2552e-01, -1.8415e-01,\n",
              "         -2.3661e-01, -8.0385e-02,  5.9139e-02,  1.6001e-01,  9.0188e-02,\n",
              "          3.6735e-03, -1.3149e-01,  1.5442e-01,  1.7577e-01, -3.5803e-02,\n",
              "          1.6228e-01, -1.6935e-01,  7.7239e-02,  1.6523e-01,  1.7767e-01,\n",
              "          3.1330e-02, -1.4593e-01,  2.4745e-01, -2.3124e-01, -5.8891e-02,\n",
              "          1.7573e-01,  1.1426e-01, -1.9109e-02, -7.5370e-02, -2.2332e-01,\n",
              "          1.1301e-01, -2.2563e-01,  2.0099e-01,  1.7373e-01,  4.4654e-02,\n",
              "          1.8809e-02, -2.6231e-02,  2.3392e-02, -8.8622e-02,  2.2047e-01,\n",
              "         -3.2448e-02,  6.4104e-02, -2.3991e-01, -2.1328e-01, -8.9690e-03,\n",
              "          7.1015e-02, -8.1902e-02, -2.4539e-01,  2.1783e-01, -1.3048e-01,\n",
              "         -5.6179e-02,  8.5709e-02,  1.3321e-01,  7.2362e-02,  1.9273e-01,\n",
              "         -1.9736e-01,  2.4497e-01, -8.6044e-02, -8.3126e-02,  1.6914e-01,\n",
              "         -1.9136e-01, -7.2598e-02,  2.2805e-01,  1.2617e-01, -1.6014e-01,\n",
              "         -1.8568e-01,  1.4607e-01, -2.4855e-01,  3.5363e-02],\n",
              "        [ 1.0248e-01,  1.5011e-01, -1.7511e-01,  8.3562e-02, -1.3889e-01,\n",
              "          1.5730e-01, -1.0430e-01,  2.0490e-01, -1.2299e-01,  1.2489e-01,\n",
              "         -2.1572e-01, -3.2593e-02, -2.3285e-01,  2.0235e-01,  4.9195e-02,\n",
              "         -2.6716e-02, -2.0840e-01, -8.6194e-04, -1.1199e-02,  3.5040e-02,\n",
              "         -2.1669e-01,  5.9153e-02, -3.9682e-02,  2.1589e-01, -5.5468e-02,\n",
              "         -7.1618e-02,  3.7726e-02,  1.0742e-02,  2.3462e-01,  1.4677e-01,\n",
              "         -1.9262e-01,  3.2347e-02,  2.3416e-01,  4.2715e-02,  8.4875e-02,\n",
              "          1.7037e-01, -1.5770e-01, -1.4607e-01, -7.0360e-02,  1.3182e-01,\n",
              "         -3.4598e-02,  2.2807e-01,  1.3115e-01, -1.1675e-01,  1.9759e-01,\n",
              "          2.3598e-01,  1.1889e-01, -2.2039e-01,  1.5628e-01,  1.5321e-01,\n",
              "         -1.2815e-01,  8.2339e-02, -3.5686e-03, -1.3219e-01,  1.6891e-01,\n",
              "          1.8879e-01, -1.8735e-01,  2.1525e-01, -9.7188e-02,  1.4989e-01,\n",
              "         -1.8656e-01,  4.8081e-02, -9.6026e-02,  1.5862e-01,  1.6670e-01,\n",
              "          5.9093e-02,  2.0893e-01, -1.0514e-01, -1.7823e-01, -5.2084e-02,\n",
              "          2.0537e-01,  2.0259e-01,  1.0367e-01, -1.7766e-01, -1.3905e-01,\n",
              "          1.1161e-01, -4.8053e-02,  2.4337e-01,  2.4542e-01,  1.6291e-01,\n",
              "         -7.7659e-02, -1.6303e-01,  1.8187e-01,  2.2144e-01],\n",
              "        [-2.7381e-03,  2.3744e-01,  1.8049e-01,  1.4223e-01, -1.5048e-01,\n",
              "         -1.3724e-01, -1.4911e-01,  2.3182e-01, -2.3801e-01, -1.4924e-01,\n",
              "         -9.1908e-02,  1.8166e-01,  2.4062e-01, -2.1672e-01, -1.3073e-01,\n",
              "          2.1084e-02, -1.4676e-01, -2.4284e-01, -2.0087e-01, -4.1064e-02,\n",
              "          5.9040e-02,  1.3637e-01,  2.0763e-01, -8.5594e-02,  1.5228e-01,\n",
              "         -8.8252e-02,  2.2344e-01,  5.6885e-02, -1.0771e-01,  1.9815e-01,\n",
              "          1.1800e-01,  2.1533e-01, -9.5198e-03, -3.5316e-02, -2.0805e-01,\n",
              "          2.8394e-02,  1.2854e-01,  1.6265e-01, -9.7812e-03,  2.4868e-01,\n",
              "         -2.4119e-01, -1.0507e-01, -1.0185e-01,  2.3636e-01, -9.4324e-02,\n",
              "          9.9312e-02, -2.2988e-02, -2.1445e-01,  1.0505e-01, -2.0882e-02,\n",
              "         -5.3130e-03,  9.9887e-02, -7.8007e-02, -2.4491e-01, -9.2522e-03,\n",
              "         -2.0708e-01,  1.8803e-01, -9.1823e-02, -8.5086e-03,  2.0546e-02,\n",
              "          2.2931e-01, -2.4568e-01,  1.6368e-02, -6.9826e-02, -9.3590e-02,\n",
              "         -1.2473e-01,  6.5535e-02, -1.8516e-01,  5.9103e-02,  2.4882e-01,\n",
              "          6.2430e-02, -6.0027e-02, -1.6003e-01, -1.6056e-01,  1.6808e-01,\n",
              "         -2.0641e-01,  1.2957e-01, -1.3070e-01, -2.1567e-01,  1.6699e-01,\n",
              "         -2.0971e-01,  1.4306e-01, -4.4769e-03,  4.6386e-02],\n",
              "        [ 1.8571e-02, -8.0291e-02, -3.5392e-02, -9.4077e-03,  1.3442e-01,\n",
              "          2.2611e-01, -2.3506e-02,  1.6822e-01, -1.9875e-01,  1.3636e-01,\n",
              "         -2.4670e-01, -6.9573e-02, -2.0539e-01, -1.9364e-01,  4.5985e-02,\n",
              "          8.0063e-02, -1.3611e-01, -2.3730e-01,  1.9840e-01, -9.6110e-02,\n",
              "          1.0370e-01,  9.5151e-03, -3.8566e-05,  1.0631e-01,  2.2112e-01,\n",
              "          1.2619e-01,  7.8270e-02, -8.4074e-02, -9.4515e-02,  3.0491e-02,\n",
              "          1.2252e-01,  4.9648e-03, -1.0980e-01,  2.3287e-01,  7.2918e-03,\n",
              "         -1.0648e-01, -8.6161e-02, -1.9482e-01,  2.2953e-02,  1.8963e-01,\n",
              "          1.4990e-02, -7.7921e-02, -1.8838e-01,  1.4161e-01,  1.0030e-01,\n",
              "          1.0059e-01,  3.2766e-02,  3.5348e-02, -2.2984e-01,  1.7256e-01,\n",
              "          7.3698e-02, -2.3976e-01, -1.9054e-01, -9.7832e-02, -5.7770e-02,\n",
              "          1.3345e-01,  3.0024e-02, -7.0840e-02,  1.9818e-01, -1.7867e-01,\n",
              "         -2.2585e-01,  1.6578e-01, -1.6652e-01, -7.3308e-02, -2.2481e-01,\n",
              "         -1.5701e-01, -3.2068e-02, -1.9021e-01, -1.7925e-01,  1.2367e-02,\n",
              "          1.4278e-02,  2.1001e-01,  2.1224e-01,  3.9328e-02, -2.4766e-01,\n",
              "          1.0605e-01, -2.2797e-01,  1.7854e-01,  1.8827e-01,  1.9685e-01,\n",
              "          1.8246e-01, -3.8005e-02,  8.9183e-02, -3.9444e-02],\n",
              "        [ 1.5144e-01,  7.6998e-02,  2.9554e-02, -2.0820e-01,  2.2388e-01,\n",
              "          2.3580e-01,  1.2878e-01, -2.4506e-01,  7.5122e-02,  2.1892e-01,\n",
              "         -1.2156e-01,  3.3740e-02, -7.6702e-02,  1.5104e-01, -1.1440e-01,\n",
              "         -1.7323e-01,  5.1539e-02, -9.4987e-02,  5.6589e-02, -5.5872e-02,\n",
              "         -2.3245e-01,  1.1103e-01, -2.4552e-01,  8.7326e-02, -2.6403e-02,\n",
              "         -4.0271e-02,  1.3571e-01,  3.7278e-02, -1.7956e-02, -1.6192e-01,\n",
              "         -2.0376e-01, -4.7950e-02,  1.0698e-01, -7.9230e-02,  1.3193e-01,\n",
              "         -2.1701e-01,  6.7491e-02, -5.4294e-02, -2.3540e-01, -1.7317e-01,\n",
              "          8.1066e-02,  1.5487e-02, -5.3861e-02, -2.4974e-01, -1.9188e-02,\n",
              "         -7.0400e-03, -1.2365e-01,  1.0445e-01, -1.8636e-01,  9.2116e-03,\n",
              "          2.0652e-01,  2.3555e-01,  1.4645e-01,  1.2702e-01, -1.1739e-01,\n",
              "          1.4857e-01, -6.9655e-02,  1.4447e-01, -9.4162e-02, -3.3086e-02,\n",
              "          3.1057e-02, -1.3080e-01, -8.7936e-02, -1.8562e-01, -1.5497e-01,\n",
              "         -1.0154e-01,  3.2080e-02, -7.6726e-02, -4.8357e-02,  4.0438e-02,\n",
              "         -4.3865e-02,  1.5580e-02, -1.3362e-01,  5.2641e-02, -1.3543e-01,\n",
              "          7.3703e-02,  7.9286e-02,  2.3816e-01, -5.0276e-02,  9.0922e-02,\n",
              "          1.8421e-01, -2.7800e-02,  7.3100e-02, -1.4337e-01],\n",
              "        [-1.2937e-01, -1.6694e-01, -5.5942e-02,  7.4013e-02,  6.7185e-02,\n",
              "          1.5013e-01,  1.8404e-01,  1.0812e-01,  8.1018e-02,  2.1162e-01,\n",
              "          2.0840e-01,  2.4516e-02, -3.2939e-02, -3.8184e-02,  2.1340e-01,\n",
              "         -2.5193e-01, -1.2904e-01,  1.3278e-01,  2.4466e-01,  3.8838e-02,\n",
              "          2.1574e-01,  3.9603e-02, -1.1423e-01, -7.8194e-02,  8.1525e-02,\n",
              "         -2.1768e-01,  7.4719e-02,  2.4449e-02, -6.1011e-02,  1.4539e-01,\n",
              "         -3.5380e-02, -2.4843e-01, -1.6923e-01,  1.2057e-01, -2.8521e-02,\n",
              "         -1.4339e-01,  8.5711e-02,  5.4750e-02, -6.0471e-02, -1.4232e-01,\n",
              "         -9.0399e-02,  2.2326e-01, -2.3555e-01,  1.8671e-01,  2.1513e-01,\n",
              "          1.7128e-01,  2.4591e-01,  1.1776e-01, -1.8881e-01,  4.5124e-02,\n",
              "         -1.5251e-02,  9.3442e-02, -1.5515e-01, -1.4461e-01,  2.4413e-01,\n",
              "          6.1000e-04,  1.9610e-02, -1.7860e-01,  2.2755e-01, -3.6662e-03,\n",
              "         -1.4061e-01, -1.8915e-01,  1.1134e-01,  1.0845e-01, -2.4096e-01,\n",
              "         -2.0356e-01,  3.8276e-02,  1.0035e-01,  6.6219e-03,  1.0093e-01,\n",
              "          6.2427e-02, -1.0907e-01, -7.0365e-02,  1.7751e-01, -1.8562e-01,\n",
              "         -2.4852e-01, -1.4661e-01, -1.6520e-01, -4.5905e-02,  2.3701e-01,\n",
              "         -1.5093e-01, -1.0615e-03, -2.0675e-02,  1.7623e-01],\n",
              "        [-9.2810e-02,  1.2176e-01, -1.3256e-01,  1.6559e-01, -2.3186e-01,\n",
              "         -1.8651e-01,  4.2536e-02, -2.2360e-01, -3.6481e-02, -2.4503e-01,\n",
              "         -6.9488e-02,  2.4052e-01,  1.5406e-01,  1.9959e-02, -1.4735e-01,\n",
              "         -8.1004e-02,  9.3360e-02,  6.7440e-02, -1.7571e-01,  5.7520e-02,\n",
              "          1.4428e-01, -2.4272e-01, -5.2586e-02, -1.7886e-01,  1.3421e-01,\n",
              "          9.9256e-02, -1.3937e-01,  1.3532e-01,  3.0462e-03,  2.1204e-01,\n",
              "          2.5593e-02, -1.6554e-01, -1.7019e-01,  8.9084e-02,  2.0678e-01,\n",
              "         -1.1699e-01, -1.3053e-01, -8.1260e-02,  1.9263e-01,  6.0430e-03,\n",
              "          1.1892e-01, -8.4176e-02,  2.1348e-01, -1.1982e-01, -8.7483e-03,\n",
              "         -1.9853e-01, -2.3439e-01, -2.3072e-01, -4.4207e-02, -1.6436e-01,\n",
              "         -1.9489e-01,  5.8207e-02,  2.9087e-02,  1.5923e-02,  1.5407e-01,\n",
              "         -1.4225e-02, -1.1063e-01,  2.4315e-01,  8.2180e-03,  5.0007e-02,\n",
              "         -1.6541e-01, -5.4888e-02, -8.4061e-02,  5.2005e-02,  1.5730e-01,\n",
              "          7.0280e-02,  5.0494e-02,  1.8765e-01, -1.4887e-01,  1.8396e-01,\n",
              "          7.1520e-02,  1.0058e-01, -2.0452e-01, -1.6894e-01,  1.6577e-01,\n",
              "         -1.3952e-02,  6.0240e-02, -4.5107e-02, -1.3459e-01,  3.4828e-02,\n",
              "         -1.1127e-01, -1.8808e-01, -2.1670e-01, -1.8958e-01],\n",
              "        [-1.4533e-01,  1.9534e-01,  2.1600e-01,  6.2654e-02,  1.2474e-01,\n",
              "         -3.7779e-02, -1.7449e-01,  1.9588e-01, -1.3045e-01, -1.5034e-03,\n",
              "         -8.6887e-02, -2.0710e-01, -1.2493e-01,  1.6710e-01, -3.3326e-03,\n",
              "          1.2862e-01,  9.4175e-03,  1.6188e-01,  1.9259e-01,  7.8928e-03,\n",
              "         -1.4970e-01, -1.0031e-02,  5.4067e-02,  1.4432e-02,  4.8744e-03,\n",
              "         -1.4492e-01, -1.5950e-04,  9.9069e-02, -1.3245e-01,  1.8700e-01,\n",
              "         -2.2988e-01, -2.2340e-01,  1.0691e-01, -2.2088e-01, -1.0950e-01,\n",
              "         -4.3151e-02,  1.9939e-01, -2.8806e-02,  5.6705e-02, -1.2915e-01,\n",
              "          1.6264e-01, -1.8158e-01,  1.6192e-01,  1.5134e-01, -2.2955e-01,\n",
              "         -6.7909e-02,  1.5411e-01, -1.9685e-01, -1.8448e-02,  2.0980e-02,\n",
              "          1.0820e-01,  3.5959e-02,  2.1329e-01,  9.6131e-02, -8.4861e-02,\n",
              "         -1.0859e-01, -1.2473e-01, -1.7170e-02, -1.1984e-01,  1.7312e-01,\n",
              "         -2.4466e-02, -7.3531e-02,  1.8400e-01, -3.0196e-02, -5.1193e-02,\n",
              "         -1.6036e-01,  1.3313e-02,  1.1431e-02, -8.7612e-02, -9.5443e-02,\n",
              "         -1.6945e-01, -2.1622e-01, -1.2218e-01, -1.1522e-01, -3.6323e-02,\n",
              "         -1.7392e-02,  1.1156e-01,  1.3734e-01,  2.1372e-01,  2.1530e-01,\n",
              "         -1.2990e-01,  1.5668e-02,  2.3237e-01, -2.3173e-01]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "train_transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
        "train_data = CIFAR10(root=\"./train/\", train=False, download=True, transform=train_transforms)\n",
        "trainloader = torch.utils.data.DataLoader( train_data, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRKMJj0BI36u",
        "outputId": "e763c102-0127-493d-cd37-2f9630c2fbd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 44309347.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./train/cifar-10-python.tar.gz to ./train/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from torch.optim import newton_cg\n",
        "import torchmin\n",
        "# from torchmin import minimize\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torchmin.Minimizer(model.parameters(),method='l-bfgs')\n"
      ],
      "metadata": {
        "id": "GW0vb9vmIQ63"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "for epoch in range(N_EPOCHS):\n",
        "  epoch_loss = 0.0\n",
        "  for inputs, labels in trainloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "\n",
        "    def closure():\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward(retain_graph=True)\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(),1.0e-2)\n",
        "\n",
        "      return loss\n",
        "    optimizer.step(closure)\n",
        "    loss = closure()\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(\"Epoch: {} Loss: {}\".format(epoch,epoch_loss/len(trainloader)))\n",
        "\n"
      ],
      "metadata": {
        "id": "45lkIbuzIVNE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "a070ef32-8410-4420-a256-b7101d44760d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-06eaf9944d86>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/optim/minimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# perform parameter update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# set final value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, method, max_iter, tol, options, callback, disp, return_all)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_lbfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/bfgs.py\u001b[0m in \u001b[0;36m_minimize_lbfgs\u001b[0;34m(fun, x0, lr, history_size, max_iter, line_search, gtol, xtol, normp, callback, disp, return_all)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moptimization\u001b[0m \u001b[0mroutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \"\"\"\n\u001b[0;32m--> 381\u001b[0;31m     return _minimize_bfgs_core(\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_mem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/bfgs.py\u001b[0m in \u001b[0;36m_minimize_bfgs_core\u001b[0;34m(fun, x0, lr, low_mem, history_size, inv_hess, max_iter, line_search, gtol, xtol, normp, callback, disp, return_all)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m#  Determine step size via strong-wolfe line search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mf_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls_evals\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mstrong_wolfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_evaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mx_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/line_search.py\u001b[0m in \u001b[0;36mstrong_wolfe\u001b[0;34m(fun, x, t, d, f, g, gtd, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# extra_codition=None. But we will keep this in case they make any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# changes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         f, g, t, ls_nevals = _strong_wolfe(\n\u001b[0m\u001b[1;32m    184\u001b[0m             fun, x.view(-1), t, d.view(-1), f, g.view(-1), gtd, **kwargs)\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mg_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mgtd_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgtd_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mf_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mls_func_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mgtd_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/optim/minimizer.py\u001b[0m in \u001b[0;36mdir_evaluate\u001b[0;34m(self, x, t, d)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_flat_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmin/optim/minimizer.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nfev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-06eaf9944d86>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bz8h1KFp0dWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}