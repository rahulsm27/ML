{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPynd9ktxrRr8d1iNO8HQ5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulsm27/ML/blob/main/Newton_Method_for_Neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SzfDHOW9ID9I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "V6P_7CeWIGlz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our own ConvNet\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "torch.nn.init.xavier_uniform_(model.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(model.conv2.weight)\n"
      ],
      "metadata": {
        "id": "LM9gGCNQIODF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824ab241-1dea-4af6-8ba7-de3eb01fb252"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[-7.1508e-03,  2.0774e-02, -9.8402e-02,  3.4959e-02,  5.1320e-02],\n",
              "          [-9.0630e-02,  3.0374e-02,  5.6665e-02,  9.9510e-02, -9.4949e-02],\n",
              "          [ 2.7301e-02,  5.5158e-02, -1.7174e-03,  6.9166e-02,  4.2873e-02],\n",
              "          [-7.9089e-03,  2.2498e-02, -9.8922e-02,  4.0853e-02,  3.8763e-02],\n",
              "          [ 2.5419e-02, -2.8185e-02, -4.5330e-02,  5.6819e-02, -4.2291e-02]],\n",
              "\n",
              "         [[ 2.3483e-02, -7.7437e-02, -5.4352e-02, -2.2201e-02, -3.2798e-02],\n",
              "          [-1.0356e-01, -1.8685e-02,  1.3590e-02,  4.8577e-02, -1.2109e-02],\n",
              "          [-6.2203e-02, -8.3368e-02,  7.4869e-03, -9.3975e-02,  8.1583e-03],\n",
              "          [ 2.3188e-02,  3.1507e-02, -8.4653e-02,  9.6460e-02, -1.1978e-02],\n",
              "          [-9.0852e-02, -7.8338e-02, -3.1433e-02,  4.3965e-02, -1.0215e-01]],\n",
              "\n",
              "         [[ 5.1529e-02,  2.9017e-02,  7.5265e-02, -3.3126e-03,  1.7804e-02],\n",
              "          [-3.4060e-02,  8.5635e-02,  1.8158e-03,  8.7742e-02, -9.8412e-02],\n",
              "          [-9.5797e-02,  2.4514e-02, -5.0812e-02, -9.9795e-02,  7.2484e-02],\n",
              "          [ 9.5288e-02, -2.1460e-02, -4.7925e-02,  7.6829e-02, -4.4855e-02],\n",
              "          [ 7.6549e-02,  2.1569e-02, -6.0774e-02,  4.6022e-02,  9.6573e-02]],\n",
              "\n",
              "         [[ 7.3883e-02,  2.1178e-02,  8.3903e-03,  7.2461e-02, -9.3265e-04],\n",
              "          [ 9.0631e-02,  6.5957e-02, -4.8971e-02, -9.3541e-02,  9.8271e-02],\n",
              "          [ 1.0111e-01,  6.2718e-02, -7.8360e-02,  6.3474e-02, -5.4918e-02],\n",
              "          [ 8.4802e-02,  2.9936e-02,  4.1851e-02,  3.5721e-02, -5.4408e-02],\n",
              "          [ 4.4046e-02, -2.4374e-02,  6.5409e-02,  4.7812e-02,  6.0617e-02]],\n",
              "\n",
              "         [[ 2.6894e-02, -5.9555e-02,  6.3398e-02,  2.9502e-02, -8.3336e-02],\n",
              "          [-4.5057e-02, -3.4666e-02,  1.0408e-01, -4.2778e-02, -7.1988e-02],\n",
              "          [-5.3313e-02, -9.6597e-02, -4.1218e-02,  9.1926e-02, -5.1061e-02],\n",
              "          [-5.1187e-02, -3.1540e-02,  1.1430e-02, -1.2351e-02,  6.1980e-02],\n",
              "          [ 5.3418e-02,  1.9200e-02,  9.6014e-02, -3.5861e-02, -3.5459e-02]],\n",
              "\n",
              "         [[ 6.3322e-03,  3.3733e-03,  2.2048e-02,  9.8689e-02, -7.3573e-02],\n",
              "          [-1.6836e-02,  2.0451e-02, -4.6043e-02, -1.0194e-01, -6.5405e-02],\n",
              "          [ 7.5722e-02, -4.3609e-02,  7.4959e-02, -5.0729e-02,  2.2436e-02],\n",
              "          [ 2.9303e-02,  2.0774e-02,  6.7849e-02,  9.3675e-02,  1.9083e-02],\n",
              "          [ 1.9143e-02, -3.3658e-02, -5.9937e-02,  4.3400e-02, -1.0311e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.5263e-02, -9.1836e-02,  7.6108e-02,  1.1397e-02, -4.5695e-02],\n",
              "          [-8.6686e-02, -4.4489e-02,  1.7974e-02,  1.0053e-01,  7.7811e-02],\n",
              "          [ 3.3415e-02,  3.6074e-02, -3.3644e-02, -4.6099e-02, -7.4907e-02],\n",
              "          [-7.0469e-02,  7.0952e-02, -8.5468e-04,  4.9477e-02,  1.7821e-02],\n",
              "          [ 4.7408e-02,  9.5720e-02, -1.2700e-02, -8.9786e-02, -8.2581e-02]],\n",
              "\n",
              "         [[-3.4627e-02, -6.5554e-02,  6.3654e-02,  2.5820e-02, -7.7127e-02],\n",
              "          [ 1.4441e-02,  8.8773e-02, -9.0481e-02, -9.8755e-02, -9.2933e-02],\n",
              "          [-4.9456e-02, -3.0966e-03,  5.8242e-02, -6.7696e-02,  3.7143e-02],\n",
              "          [ 1.1701e-02, -8.6806e-02,  5.1209e-02, -6.9655e-02, -8.9196e-02],\n",
              "          [ 1.0316e-01,  7.4199e-03, -5.9140e-02, -6.8779e-02,  7.1112e-02]],\n",
              "\n",
              "         [[-9.6072e-03, -9.2992e-02,  6.8798e-02, -6.4975e-02, -5.9699e-02],\n",
              "          [-2.9368e-02,  9.5425e-02,  4.7517e-02,  5.8995e-02,  5.8690e-02],\n",
              "          [-6.2052e-02, -5.6805e-02, -9.3697e-02, -8.5300e-02,  5.0242e-02],\n",
              "          [-4.0974e-02,  5.0887e-02,  4.4782e-02, -5.5596e-02,  1.2264e-02],\n",
              "          [-4.6260e-02, -3.8454e-03,  9.6229e-02,  9.2280e-02, -1.1392e-03]],\n",
              "\n",
              "         [[ 6.7921e-02, -7.3142e-02,  2.3192e-02,  8.5283e-02,  5.5081e-02],\n",
              "          [ 4.4147e-02,  7.1130e-02,  2.6257e-02, -7.4381e-02, -3.4614e-02],\n",
              "          [-3.2347e-02,  8.1484e-02, -3.6467e-02,  8.3864e-02, -3.4015e-02],\n",
              "          [-1.2675e-02,  9.8675e-02,  1.0258e-01, -1.0201e-01,  9.7929e-03],\n",
              "          [ 1.1429e-03, -2.7037e-02, -5.8950e-02,  1.2707e-02, -2.3946e-02]],\n",
              "\n",
              "         [[-6.5923e-03, -6.4839e-02,  6.6476e-03,  8.9942e-03, -4.8826e-03],\n",
              "          [ 3.6580e-02,  8.7423e-02, -5.0874e-02,  2.3128e-02,  3.3191e-02],\n",
              "          [ 4.1533e-02, -6.9587e-02,  6.8132e-02,  9.7981e-02,  2.7072e-02],\n",
              "          [-6.4744e-02, -8.6960e-02, -5.3241e-02,  2.4070e-02,  9.0328e-02],\n",
              "          [ 2.9152e-02,  1.1101e-02, -9.9659e-02,  6.9118e-02,  1.9627e-02]],\n",
              "\n",
              "         [[-7.2212e-02,  2.2885e-02, -8.3903e-02, -9.2012e-02, -3.0226e-02],\n",
              "          [-9.0742e-03,  4.7590e-02, -9.8048e-02,  2.6959e-02, -2.1909e-02],\n",
              "          [ 4.7834e-02,  4.7011e-02, -6.2067e-02, -1.6258e-02, -5.6567e-02],\n",
              "          [-4.3600e-03,  5.2337e-02, -6.7488e-03, -7.2856e-02,  4.9590e-02],\n",
              "          [ 5.4617e-02,  9.3810e-02,  4.4226e-02, -4.9636e-02,  9.2986e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9113e-02, -1.9616e-03,  9.6085e-02, -4.3059e-02,  7.7457e-02],\n",
              "          [-1.0565e-02,  7.3713e-02,  9.9022e-04, -6.8514e-02,  2.4225e-02],\n",
              "          [-2.0191e-02, -1.0213e-01,  9.0479e-02,  8.8182e-02,  6.3427e-02],\n",
              "          [-5.8725e-02, -5.2205e-02, -8.5751e-02,  2.6900e-02,  7.6150e-02],\n",
              "          [-2.1969e-02, -6.5499e-02,  4.4014e-03, -9.0620e-02,  2.1922e-02]],\n",
              "\n",
              "         [[-2.3513e-02, -3.2932e-02,  1.3427e-02,  1.7287e-02,  2.9406e-03],\n",
              "          [-8.5898e-02, -8.9516e-02, -2.7095e-02,  4.1571e-02,  8.4829e-02],\n",
              "          [-6.3517e-02,  9.5139e-02, -2.0875e-02, -5.7405e-02,  6.1352e-02],\n",
              "          [ 2.2156e-02,  3.3636e-02, -4.3196e-02,  1.4316e-02, -3.4126e-02],\n",
              "          [-9.7739e-02,  4.8958e-02,  7.0688e-02, -7.4931e-02, -9.6304e-03]],\n",
              "\n",
              "         [[ 4.0307e-02, -4.5681e-02, -1.5920e-02,  7.6817e-02, -6.4341e-02],\n",
              "          [ 3.9243e-02, -1.5591e-02, -7.5072e-02, -9.7386e-02, -1.0225e-01],\n",
              "          [-1.2744e-02,  6.3799e-02, -8.7424e-02,  2.4996e-02,  7.8696e-02],\n",
              "          [ 5.9351e-02,  5.4306e-02,  9.8624e-02,  2.0924e-02, -8.3138e-02],\n",
              "          [ 5.3897e-02,  1.2699e-02,  9.4800e-02,  1.0169e-01,  3.0884e-02]],\n",
              "\n",
              "         [[-4.3296e-02,  3.0924e-02, -8.2443e-02,  3.5492e-02, -4.5224e-03],\n",
              "          [-8.7763e-02,  6.0665e-02,  8.1675e-02,  1.0534e-03,  2.0817e-02],\n",
              "          [ 8.4679e-03,  7.3282e-02,  2.4693e-02,  7.6446e-02, -1.7234e-02],\n",
              "          [-6.8566e-02, -9.3772e-02,  4.5065e-02,  9.8714e-02,  3.7131e-02],\n",
              "          [ 7.1964e-02,  2.7004e-02,  9.6000e-02, -2.4020e-02, -2.1829e-02]],\n",
              "\n",
              "         [[-6.1810e-02, -2.7020e-02, -4.4701e-02,  6.7862e-02, -1.8107e-02],\n",
              "          [ 1.0303e-01, -1.2801e-03,  8.5088e-02, -9.9071e-02, -2.6969e-02],\n",
              "          [ 3.5213e-02, -3.8812e-02,  6.8805e-02,  6.0089e-02, -5.5674e-02],\n",
              "          [-1.5917e-02,  7.5825e-02,  4.7908e-02,  8.8215e-02,  3.5210e-02],\n",
              "          [-9.6971e-02,  2.4624e-02, -4.3078e-02, -2.9231e-02,  4.4012e-02]],\n",
              "\n",
              "         [[-1.4438e-02,  6.1985e-02,  9.0323e-02,  1.0319e-01, -1.7793e-02],\n",
              "          [ 4.8690e-02,  1.6716e-02, -4.9568e-02, -4.6761e-02,  7.0102e-02],\n",
              "          [-4.0339e-02, -9.8693e-02, -5.1695e-03,  1.8560e-02,  8.6915e-02],\n",
              "          [ 4.1991e-02,  8.8538e-02,  2.8754e-02,  1.8495e-03,  9.8244e-02],\n",
              "          [-4.6053e-02, -2.9150e-02, -6.0023e-02,  3.7124e-02, -6.6887e-02]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-2.8004e-03,  2.6966e-02,  8.1348e-02, -8.0697e-02, -2.9731e-02],\n",
              "          [ 3.5429e-03, -1.8866e-02,  2.3680e-02, -6.1762e-02,  7.9521e-02],\n",
              "          [-4.4468e-02,  6.8563e-02, -4.6669e-02, -8.0508e-02,  7.9087e-02],\n",
              "          [ 9.9717e-02,  6.4874e-02, -8.8725e-02, -3.5155e-03, -8.0381e-02],\n",
              "          [ 8.8635e-02, -2.1105e-03, -8.5767e-02, -1.4427e-02,  3.2173e-02]],\n",
              "\n",
              "         [[ 5.7646e-02,  4.6063e-03, -5.8170e-02,  5.6525e-02,  4.0127e-03],\n",
              "          [ 4.7459e-03,  1.8076e-02,  5.1355e-02,  5.3049e-02, -7.0585e-02],\n",
              "          [ 1.7495e-02, -4.1711e-02, -5.7918e-02,  1.0701e-02,  7.6392e-02],\n",
              "          [-5.7871e-02, -5.3488e-02, -1.0090e-01, -1.7024e-02, -6.9433e-02],\n",
              "          [ 1.4546e-02,  5.3058e-03,  2.9463e-02,  7.7102e-02, -6.4041e-02]],\n",
              "\n",
              "         [[ 4.6909e-04,  5.0035e-02,  3.1852e-02, -2.1159e-02,  9.5148e-02],\n",
              "          [ 2.3073e-02, -2.1244e-03,  3.3436e-02, -1.5224e-02, -9.7551e-02],\n",
              "          [-1.4640e-02,  4.1566e-02,  5.9323e-02, -9.2524e-02,  1.3189e-02],\n",
              "          [ 1.6388e-02,  4.8007e-02,  2.1286e-02, -2.8820e-02,  6.4272e-02],\n",
              "          [-2.8057e-02, -5.8767e-02, -3.3774e-02, -7.2175e-02, -8.2286e-02]],\n",
              "\n",
              "         [[-2.0369e-02, -4.5560e-02,  1.8305e-02,  1.4832e-03,  6.2796e-02],\n",
              "          [ 6.6649e-02,  5.8635e-02, -5.4286e-02,  4.5706e-02, -2.2711e-03],\n",
              "          [ 4.7007e-02, -8.1595e-02, -3.1033e-02,  1.7617e-02, -8.9309e-02],\n",
              "          [ 1.4834e-02, -6.8312e-02,  4.6291e-02,  1.5322e-02,  3.6935e-02],\n",
              "          [-5.9185e-02, -1.2237e-02, -9.5262e-02,  6.0424e-02, -5.3261e-02]],\n",
              "\n",
              "         [[-5.9940e-02,  1.5131e-02, -9.6345e-03,  5.6326e-02, -6.5784e-02],\n",
              "          [ 1.0399e-01, -8.5378e-02, -2.5733e-02,  7.6805e-02,  1.5058e-02],\n",
              "          [ 4.7167e-02,  9.8102e-02,  3.0169e-02,  1.1676e-02, -1.2358e-02],\n",
              "          [ 5.0997e-03,  7.5815e-02, -5.3836e-02,  3.8826e-02,  9.1145e-03],\n",
              "          [-2.4206e-02, -4.9643e-02,  1.5834e-02, -6.1290e-03, -9.2076e-02]],\n",
              "\n",
              "         [[ 4.6535e-03,  9.2991e-02,  1.7160e-02,  8.8969e-02, -5.7023e-02],\n",
              "          [-3.1415e-02, -1.9043e-02, -7.6997e-02, -4.2798e-02, -6.1472e-03],\n",
              "          [-6.6350e-03,  9.8001e-02,  1.0366e-01,  9.5750e-02,  4.2051e-02],\n",
              "          [-7.0380e-02, -7.0863e-02, -7.4350e-02, -1.0187e-01, -2.3736e-02],\n",
              "          [-2.3635e-02, -1.9826e-02, -8.8614e-02,  4.4937e-02,  2.4697e-02]]],\n",
              "\n",
              "\n",
              "        [[[-9.9508e-02,  2.4870e-02,  2.1155e-02,  8.4645e-02,  1.9425e-02],\n",
              "          [ 4.8737e-02, -2.3655e-02, -7.5488e-02,  1.9006e-02, -1.9692e-02],\n",
              "          [ 4.4161e-02,  1.8985e-02,  8.4173e-02,  7.3429e-02, -3.2390e-02],\n",
              "          [-7.4643e-02, -6.6812e-02,  4.7187e-02,  7.9254e-02,  6.2301e-02],\n",
              "          [ 9.8250e-02,  4.3591e-02,  6.9661e-02,  2.0301e-02,  9.4717e-02]],\n",
              "\n",
              "         [[ 7.9733e-02, -1.2900e-02,  2.4866e-03, -2.3918e-02,  8.3502e-02],\n",
              "          [ 1.6294e-02, -7.8268e-02,  5.0539e-05, -5.9743e-02,  5.8460e-02],\n",
              "          [-4.5652e-02,  5.1031e-02,  6.9366e-02, -6.7750e-02, -1.1066e-02],\n",
              "          [ 5.1646e-02,  7.9137e-02, -1.0426e-01, -8.8671e-02, -1.5953e-02],\n",
              "          [-5.4145e-02,  7.3278e-02,  1.0071e-01,  8.2251e-02,  8.1986e-02]],\n",
              "\n",
              "         [[-7.3552e-02,  2.5512e-02, -7.5772e-02,  6.1827e-02, -7.9188e-02],\n",
              "          [ 1.0032e-01,  4.1720e-02, -4.8151e-02,  4.3094e-02, -1.8950e-02],\n",
              "          [-3.4685e-02,  6.9428e-02,  3.5702e-02, -8.2798e-02, -2.2928e-02],\n",
              "          [ 3.2774e-03,  9.3874e-02,  7.0436e-03, -2.1376e-03,  8.5192e-02],\n",
              "          [ 3.3435e-02, -8.5919e-02,  9.8485e-02,  2.0260e-02,  5.7513e-02]],\n",
              "\n",
              "         [[ 1.0034e-01,  2.4237e-02,  1.5214e-02,  4.8319e-02, -6.0598e-02],\n",
              "          [ 5.6185e-02,  2.9867e-02,  6.1544e-02,  1.6159e-02,  5.4519e-02],\n",
              "          [ 7.3086e-03,  6.6430e-02,  6.0016e-02, -2.1067e-02,  8.7926e-02],\n",
              "          [-5.4031e-02,  4.8864e-02,  2.8553e-02, -1.3929e-02, -2.8761e-02],\n",
              "          [ 4.4935e-03, -1.0338e-01,  6.4994e-02, -6.0568e-02,  1.2583e-02]],\n",
              "\n",
              "         [[ 9.4676e-02,  7.8870e-02,  1.2499e-03,  1.7772e-02,  8.5145e-02],\n",
              "          [-5.8983e-02,  5.2790e-02,  5.9648e-04,  5.5065e-02,  4.8167e-04],\n",
              "          [ 2.2486e-02, -8.2620e-02, -6.7236e-02, -6.4515e-02, -3.9261e-02],\n",
              "          [ 6.5211e-02, -9.0162e-02,  1.4154e-03,  3.5732e-02,  3.0287e-02],\n",
              "          [ 9.7574e-02,  7.0892e-02,  7.1424e-03,  1.8046e-02,  9.1525e-02]],\n",
              "\n",
              "         [[-2.8941e-02,  2.9173e-02,  2.8122e-02, -5.2731e-02,  1.0243e-01],\n",
              "          [-8.9847e-03, -1.3048e-02,  1.0307e-01,  9.6478e-02,  3.0093e-02],\n",
              "          [ 1.0313e-01,  9.1227e-02,  9.9729e-02,  9.0836e-02, -4.7294e-02],\n",
              "          [ 7.5883e-02, -1.9512e-02, -7.8467e-02, -7.4508e-02,  3.8822e-02],\n",
              "          [-2.9742e-02,  7.1352e-02,  9.4691e-02,  2.6437e-02,  1.6273e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.8122e-02, -1.4448e-03,  3.9840e-02,  2.8204e-02, -7.6044e-02],\n",
              "          [-9.0936e-02, -1.0365e-01,  5.7583e-02,  5.6329e-03, -8.7245e-03],\n",
              "          [-9.1469e-02,  4.5473e-02, -7.3028e-02,  9.4973e-02,  9.2906e-02],\n",
              "          [-7.6021e-02,  8.8277e-02, -1.3207e-02, -5.5599e-02,  6.0385e-02],\n",
              "          [ 5.5644e-02, -3.4818e-03,  7.2656e-02, -1.0143e-01,  9.8280e-02]],\n",
              "\n",
              "         [[-7.9413e-02,  1.1195e-02,  8.6632e-02, -1.0017e-01,  8.7937e-02],\n",
              "          [ 7.5563e-02,  1.5792e-02, -8.3916e-02,  1.0138e-01,  5.8936e-03],\n",
              "          [-7.3130e-02, -1.8459e-02,  9.5107e-02,  4.8384e-02, -1.4872e-02],\n",
              "          [-4.3154e-02, -6.1494e-02, -3.9775e-03,  7.3206e-03, -1.5312e-02],\n",
              "          [ 5.3514e-03,  5.3295e-02, -2.5827e-03, -3.6628e-02, -1.9520e-03]],\n",
              "\n",
              "         [[ 8.0801e-02,  9.9012e-02,  3.4075e-02, -5.8151e-02,  6.5913e-02],\n",
              "          [-1.4615e-02, -3.4076e-03, -7.8599e-02, -9.0270e-02,  2.5284e-02],\n",
              "          [-6.2640e-02, -8.5567e-02, -4.1344e-02, -2.0777e-03, -7.5010e-02],\n",
              "          [ 1.4372e-02,  8.8410e-02, -8.9862e-02, -5.6557e-02,  8.0640e-02],\n",
              "          [ 8.3911e-02,  8.8449e-02, -2.3377e-03, -6.9254e-02,  1.0355e-01]],\n",
              "\n",
              "         [[ 9.7666e-02,  6.0171e-02, -3.7250e-02, -7.9068e-02, -2.1393e-02],\n",
              "          [ 1.0026e-02, -2.5411e-02,  5.1283e-02,  3.8160e-02, -6.0364e-02],\n",
              "          [-3.2406e-02,  4.3486e-02, -3.0164e-02,  1.7754e-02, -4.0678e-02],\n",
              "          [ 7.1737e-02, -6.8506e-02, -3.5046e-02,  7.9070e-02,  1.1123e-02],\n",
              "          [ 3.3541e-02, -1.0224e-01,  8.0235e-02,  4.3026e-02, -5.6026e-02]],\n",
              "\n",
              "         [[-6.9252e-02, -4.6757e-02, -2.6733e-02, -5.2908e-02, -5.0986e-02],\n",
              "          [-7.3197e-02, -3.7006e-02, -5.9699e-02, -2.8919e-02,  7.4472e-02],\n",
              "          [ 4.5461e-02, -5.3915e-02, -6.9576e-02,  1.8200e-03,  8.1741e-02],\n",
              "          [ 8.9955e-02, -5.4733e-02,  1.1900e-02,  9.8384e-02,  4.6423e-02],\n",
              "          [ 2.9433e-02,  8.0394e-03,  3.5666e-02,  4.4427e-02, -2.0884e-02]],\n",
              "\n",
              "         [[-5.1372e-02,  6.9480e-02,  1.5785e-02, -6.1331e-02,  7.2855e-02],\n",
              "          [-9.0563e-02,  2.3856e-02, -9.6537e-02,  2.8735e-02, -9.6658e-02],\n",
              "          [-2.1180e-02, -4.5412e-02,  1.1823e-02, -3.9752e-02,  5.6389e-02],\n",
              "          [ 1.3546e-02, -5.2391e-02,  6.3292e-02,  1.2168e-02, -8.4256e-02],\n",
              "          [-3.9580e-02, -4.0497e-02, -1.0136e-01,  5.6390e-02, -5.9732e-03]]]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "train_transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
        "train_data = CIFAR10(root=\"./train/\", train=True, download=True, transform=train_transforms)\n",
        "trainloader = torch.utils.data.DataLoader( train_data, batch_size=512,shuffle=True)\n",
        "\n",
        "test_data = CIFAR10(root=\"./test/\", train=False, download=True, transform=train_transforms)\n",
        "testloader = torch.utils.data.DataLoader( test_data,batch_size=512, shuffle=True)"
      ],
      "metadata": {
        "id": "CRKMJj0BI36u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94fc2ed5-5990-4670-a24b-002cc83f111d"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.LBFGS(model.parameters(),lr=0.39,max_iter=4,history_size=10,line_search_fn='strong_wolfe')\n",
        "\n"
      ],
      "metadata": {
        "id": "GW0vb9vmIQ63"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "for epoch in range(N_EPOCHS):\n",
        "  epoch_loss = 0.0\n",
        "  i = 0\n",
        "  model.train()\n",
        "  for inputs, labels in trainloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    def closure():\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward(retain_graph=True)\n",
        "      global epoch_loss\n",
        "      epoch_loss += loss.item()\n",
        "  #    print(loss.item())\n",
        "      return loss\n",
        "\n",
        "    optimizer.step(closure)\n",
        "\n",
        "\n",
        "\n",
        "  val_loss = 0.0\n",
        "  model.eval()\n",
        "  for inputs, labels in testloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    val_loss += loss.item()\n",
        "  print(\"Epoch: {} Train Loss: {} Val Loss: {} \".format(epoch, epoch_loss/len(trainloader), val_loss/len(testloader)))\n",
        "\n"
      ],
      "metadata": {
        "id": "45lkIbuzIVNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38a4fc7-4a4f-4515-8371-2b4b67a49b90"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train Loss: 4629.119049381236 Val Loss: 1.6341470539569856 \n",
            "Epoch: 1 Train Loss: 10.338928778560794 Val Loss: 1.6306005775928498 \n",
            "Epoch: 2 Train Loss: 7.531226352769501 Val Loss: 1.6276377320289612 \n",
            "Epoch: 3 Train Loss: 8.307211396645526 Val Loss: 1.6254245519638062 \n",
            "Epoch: 4 Train Loss: 9.13040437625379 Val Loss: 1.6163111627101898 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(test_data[9][0].unsqueeze(0).to(device))\n",
        "print(f\" Model predicted label : {np.argmax(y_pred.detach().cpu().numpy())}\")\n",
        "print(f\" Actual label : {test_data[9][1]}\")"
      ],
      "metadata": {
        "id": "Bz8h1KFp0dWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6a88ee-0691-408a-a0cd-7cb40bf2bf28"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model predicted label : 1\n",
            " Actual label : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A5RFHBBMYoZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}