{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuGaByXTJ3JrNnT2jIu+68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulsm27/ML/blob/main/Newton_Method_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5BRkth9IkLc3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from utils import compute_stats, get_grad\n",
        "from LBFGS import FullBatchLBFGS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "G08htogzk8sZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our own LeNet5\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5) # in channel , out channe, kernel\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.maxpool1 = nn.MaxPool2d((2,2))\n",
        "\n",
        "    self.conv2 = nn.Conv2d(6,16,5)  # in channel , out channe, kernel\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.maxpool2 = nn.MaxPool2d((2,2))\n",
        "\n",
        "    self.fc1 = nn.Linear(16*5*5,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    x = self.relu1(x)\n",
        "    x= self.maxpool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu2(x)\n",
        "    x= self.maxpool2(x)\n",
        "\n",
        "    x = x.view(-1,int(x.nelement() / x.shape[0]))\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "model = LeNet5().to(device)\n",
        "torch.nn.init.xavier_uniform_(model.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(model.conv2.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZvdrL51k7rY",
        "outputId": "efb5c0c1-e5f1-4f28-bec0-b5acf84f7442"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[ 3.0787e-02, -6.2263e-02, -5.1466e-02,  3.8122e-02,  3.2720e-02],\n",
              "          [ 2.4915e-02, -7.6524e-02, -5.7436e-02, -1.0001e-01, -1.8606e-02],\n",
              "          [-1.0129e-01,  3.5482e-02,  7.8135e-02, -1.0223e-01, -9.1828e-02],\n",
              "          [ 2.7611e-02, -4.4325e-02,  5.1430e-02,  1.7977e-02, -6.9935e-02],\n",
              "          [-4.2182e-03,  4.6309e-02, -1.8666e-02, -7.8248e-02,  2.3244e-02]],\n",
              "\n",
              "         [[ 9.9645e-02, -6.8276e-02,  4.1207e-02,  1.0047e-01,  9.3279e-02],\n",
              "          [ 5.1429e-02,  3.5563e-02, -7.3050e-02, -4.5599e-02, -7.8214e-02],\n",
              "          [-8.7034e-02,  9.5617e-03,  2.2930e-02,  8.6502e-02, -1.0082e-01],\n",
              "          [-8.8730e-02, -1.5538e-02, -9.0158e-02,  3.5200e-03, -4.2291e-02],\n",
              "          [-4.1865e-02,  4.3006e-02,  4.0019e-02, -8.6938e-02,  4.0544e-02]],\n",
              "\n",
              "         [[-3.5522e-02,  9.9218e-02,  4.2517e-02,  4.5931e-03,  8.0518e-02],\n",
              "          [-5.4824e-02, -3.4293e-02,  7.6069e-02,  9.5703e-02,  3.5839e-02],\n",
              "          [ 7.0171e-02, -5.3860e-02,  2.1003e-02,  9.0772e-02,  1.0611e-03],\n",
              "          [-6.5143e-02, -1.5996e-02, -6.9291e-02,  6.5295e-03,  9.8755e-02],\n",
              "          [ 8.0366e-02,  7.4153e-02, -3.6989e-02, -1.0801e-02, -4.2782e-02]],\n",
              "\n",
              "         [[-4.2143e-02,  4.0173e-02,  3.0186e-02, -2.0277e-02,  1.0056e-01],\n",
              "          [ 2.8380e-02,  9.0383e-02, -1.2643e-03,  9.1624e-02,  7.2576e-02],\n",
              "          [ 2.6148e-02,  9.6468e-02,  5.0248e-02, -4.8468e-02, -4.8676e-02],\n",
              "          [-8.6314e-02,  2.4581e-02,  1.2011e-02,  2.8565e-02, -9.2632e-02],\n",
              "          [-1.4529e-03,  7.0916e-02, -5.1244e-02, -9.6831e-02, -6.5836e-02]],\n",
              "\n",
              "         [[ 4.2980e-02, -2.1948e-02, -9.1589e-02,  7.1802e-02,  3.2581e-02],\n",
              "          [-3.1711e-02,  6.4159e-02,  7.4530e-02, -7.8480e-03, -7.6278e-02],\n",
              "          [ 8.5775e-02, -4.6745e-03, -6.7079e-02, -8.8379e-02, -1.6194e-02],\n",
              "          [ 1.0437e-01, -9.4397e-02,  9.5729e-02,  7.0515e-02,  2.2907e-02],\n",
              "          [ 1.0788e-02,  9.8832e-02, -3.7297e-02,  6.1174e-02, -1.0321e-01]],\n",
              "\n",
              "         [[-1.7383e-02,  1.9772e-02,  2.7064e-02, -4.0589e-03,  6.0755e-02],\n",
              "          [ 5.5447e-02, -9.2394e-02, -6.5604e-02,  8.7785e-02,  3.9636e-02],\n",
              "          [-2.2822e-02,  4.6483e-02, -1.4085e-02,  1.6809e-02,  5.3934e-03],\n",
              "          [-7.4209e-03, -9.8509e-02, -2.4144e-02,  8.2571e-02,  1.3068e-02],\n",
              "          [-9.6413e-02, -5.2831e-02,  2.5027e-02,  8.7231e-02,  1.8772e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0309e-01, -4.7662e-02,  2.0614e-02,  1.0014e-01, -8.9118e-02],\n",
              "          [ 3.1515e-02,  7.5365e-02, -6.0980e-02, -9.7790e-03,  1.4577e-02],\n",
              "          [-6.6342e-03,  6.4272e-02, -3.7453e-02, -9.7483e-02,  7.1894e-02],\n",
              "          [ 9.7188e-02, -3.9852e-02,  6.4753e-02, -2.1967e-02,  5.4756e-02],\n",
              "          [-5.4790e-02, -1.7178e-02,  6.8951e-02, -3.8863e-02, -9.7743e-03]],\n",
              "\n",
              "         [[ 9.3584e-02, -9.2352e-03, -1.5441e-02,  1.6368e-02, -9.8451e-02],\n",
              "          [ 3.5504e-02, -7.8576e-02, -3.2191e-02,  9.0207e-02,  9.9037e-02],\n",
              "          [ 2.7015e-02, -9.6040e-02, -5.3985e-02, -7.0074e-02, -5.2786e-02],\n",
              "          [-9.5616e-02,  8.8761e-02,  3.7257e-03,  3.0428e-02, -7.1919e-02],\n",
              "          [ 2.8315e-02, -5.0296e-02, -7.7100e-02, -7.2347e-02, -1.5186e-02]],\n",
              "\n",
              "         [[ 8.2924e-06,  9.5396e-02, -9.8622e-02,  5.5731e-02,  6.9872e-02],\n",
              "          [-8.0237e-02, -3.4433e-02, -9.3716e-02,  9.4914e-02, -3.1013e-02],\n",
              "          [-4.3453e-02, -6.1382e-02,  9.7668e-02,  3.2966e-02, -2.5803e-02],\n",
              "          [ 9.9264e-02,  3.3019e-03, -8.1821e-02, -8.1163e-02, -1.0201e-01],\n",
              "          [ 5.4998e-02,  3.0608e-02, -6.9661e-03,  5.1205e-02, -9.6977e-02]],\n",
              "\n",
              "         [[-6.1927e-02,  1.6258e-02, -2.9365e-02,  8.3316e-02, -9.2281e-02],\n",
              "          [ 6.2096e-02, -1.2215e-02,  1.2505e-02, -9.5400e-02,  9.1374e-02],\n",
              "          [-7.2596e-03, -4.5289e-02,  1.0295e-02, -5.7577e-02,  1.2645e-02],\n",
              "          [-5.1927e-02,  9.2045e-02,  1.9092e-02,  8.7084e-02,  8.6118e-02],\n",
              "          [-8.7130e-02,  8.9321e-02, -4.7300e-02,  2.0179e-02,  5.8365e-02]],\n",
              "\n",
              "         [[ 2.8915e-02, -4.4135e-02, -1.6766e-02, -4.8596e-02,  5.7775e-02],\n",
              "          [-9.8866e-02, -5.3495e-03,  2.9804e-02, -6.5460e-02, -5.0499e-02],\n",
              "          [-9.2883e-02,  4.2464e-02,  5.0357e-02, -7.9250e-02, -2.9215e-02],\n",
              "          [ 2.0791e-02,  9.1981e-03,  8.1851e-02, -2.4703e-03, -3.8501e-02],\n",
              "          [ 5.7081e-02,  1.0095e-01, -2.2588e-02,  4.8905e-02,  9.7767e-02]],\n",
              "\n",
              "         [[-4.7829e-02,  5.3048e-02, -2.4284e-02,  7.2921e-02, -5.7760e-02],\n",
              "          [-3.0509e-02,  7.4194e-02,  1.0052e-01, -1.0167e-01,  7.9856e-02],\n",
              "          [ 6.4905e-02,  1.7290e-02,  1.0409e-01,  2.2833e-02, -1.3699e-02],\n",
              "          [-2.8232e-02, -1.0235e-03,  3.7746e-02, -1.4487e-02,  2.9410e-02],\n",
              "          [ 7.2326e-03, -3.8828e-02, -6.4787e-02,  3.4773e-02,  6.9935e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 4.9339e-02,  7.8603e-03,  1.5747e-04,  2.3570e-03,  5.2960e-02],\n",
              "          [ 2.5323e-02, -7.3078e-03, -3.3797e-02,  8.2160e-02,  1.1345e-02],\n",
              "          [ 4.4343e-02, -9.5554e-02, -9.4482e-02,  9.6941e-02, -1.2195e-02],\n",
              "          [ 5.2463e-02, -7.0961e-02, -4.5385e-02, -7.9005e-02,  5.8929e-02],\n",
              "          [-2.6497e-02,  7.2625e-02, -8.9721e-02,  5.1484e-02,  8.2248e-02]],\n",
              "\n",
              "         [[-4.7115e-02, -1.7190e-02, -6.7239e-03,  6.1892e-02, -4.3431e-02],\n",
              "          [-1.0052e-01,  4.4355e-02, -1.0075e-01, -1.9244e-02,  2.9871e-02],\n",
              "          [ 3.8941e-02,  8.5852e-03, -8.9827e-02, -3.3703e-02,  5.8843e-02],\n",
              "          [ 4.1686e-02,  1.8094e-02, -1.6142e-02,  5.8984e-02, -8.9794e-02],\n",
              "          [-9.0210e-02,  7.5656e-02,  8.1782e-02, -7.7375e-02, -7.0514e-02]],\n",
              "\n",
              "         [[ 2.8479e-02, -4.0439e-02,  3.4860e-02,  6.0808e-03,  8.0510e-02],\n",
              "          [-9.2026e-02, -4.0700e-02, -1.0391e-01, -2.4635e-02, -9.7514e-02],\n",
              "          [-1.0208e-02,  2.2929e-02, -6.9986e-02, -5.3547e-02,  9.1101e-02],\n",
              "          [ 7.3915e-02, -2.4490e-02,  5.8017e-02,  4.0614e-03,  6.2678e-02],\n",
              "          [-3.8426e-02, -7.9469e-02, -5.5857e-02,  9.5941e-02,  4.3328e-02]],\n",
              "\n",
              "         [[ 1.0338e-01, -6.4533e-02, -8.9640e-02, -2.5194e-02,  6.1714e-02],\n",
              "          [-3.3262e-02, -7.0108e-02, -1.7080e-03, -9.2427e-02,  9.5945e-02],\n",
              "          [ 8.7895e-02,  4.1002e-02,  3.4552e-02,  3.5055e-02,  7.7191e-02],\n",
              "          [-1.7205e-02, -5.7927e-02,  5.5777e-02, -3.4114e-02,  8.9071e-02],\n",
              "          [-8.7248e-03, -2.7075e-02, -4.7391e-02,  3.4576e-02, -6.5923e-02]],\n",
              "\n",
              "         [[-2.1650e-03, -8.9607e-02, -6.5472e-02,  7.1312e-02, -9.3113e-02],\n",
              "          [ 1.0655e-02,  9.6707e-02, -4.0709e-02, -8.9263e-02,  8.7474e-02],\n",
              "          [-8.8767e-02,  3.2401e-02, -5.9414e-03, -4.6843e-03, -2.8546e-02],\n",
              "          [ 1.9211e-02,  7.6090e-02, -3.2067e-02, -4.5628e-02,  5.8170e-02],\n",
              "          [ 6.4296e-02, -3.0298e-02,  6.6324e-02,  4.4371e-02, -3.2285e-02]],\n",
              "\n",
              "         [[ 1.0248e-01, -1.3752e-02, -3.9877e-02,  9.3890e-02, -5.7454e-02],\n",
              "          [-9.4566e-02,  8.5598e-02,  7.1892e-02, -1.4974e-02,  1.8672e-02],\n",
              "          [ 6.7364e-02,  1.0304e-02,  3.8773e-02, -3.6525e-02, -1.7982e-02],\n",
              "          [ 4.7281e-03, -5.3026e-02,  3.0752e-02, -4.7796e-02,  4.0579e-02],\n",
              "          [-1.0022e-01, -8.6163e-02,  4.2313e-02,  2.2074e-02,  8.2664e-02]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[ 8.0992e-02, -8.5539e-02,  6.4096e-02,  1.4883e-02,  4.9210e-02],\n",
              "          [ 5.0996e-03,  3.7856e-02, -3.3809e-02,  1.0370e-01, -3.2510e-02],\n",
              "          [-4.5082e-02,  7.5224e-02,  3.4716e-02, -9.6955e-02,  1.5155e-02],\n",
              "          [-5.7197e-02, -2.7630e-02,  2.2080e-02,  9.5093e-02, -1.3924e-02],\n",
              "          [-1.0428e-01, -3.2957e-02, -6.1261e-02, -5.2744e-02, -5.3223e-02]],\n",
              "\n",
              "         [[ 6.4409e-02, -1.9876e-03,  7.3626e-02, -8.5391e-02, -3.8373e-02],\n",
              "          [ 2.5532e-02,  1.8738e-02, -4.0909e-02, -9.2911e-02, -3.5532e-02],\n",
              "          [ 4.1989e-02,  1.5876e-02,  7.2006e-02,  8.9588e-03, -1.9593e-02],\n",
              "          [-8.6799e-02, -3.9949e-02, -2.0209e-02,  5.7709e-02,  9.7636e-03],\n",
              "          [ 3.7891e-03, -5.1603e-02, -2.6761e-02,  6.8692e-02, -5.6291e-02]],\n",
              "\n",
              "         [[ 3.4149e-02, -2.7689e-02,  2.1843e-02, -9.3379e-03, -9.1819e-03],\n",
              "          [-1.0021e-01,  3.7703e-02,  1.3141e-02,  3.8582e-02,  3.8359e-03],\n",
              "          [ 8.4993e-02, -3.0385e-02,  2.2961e-02, -7.0468e-02,  2.9952e-02],\n",
              "          [ 5.2950e-02,  8.4738e-02, -7.7530e-02, -1.6787e-02, -8.5086e-02],\n",
              "          [-8.7282e-02, -8.7740e-02,  2.9992e-02, -1.8404e-02, -9.7951e-02]],\n",
              "\n",
              "         [[-1.0380e-01,  1.3988e-02, -4.1889e-02,  9.7819e-02, -8.3919e-02],\n",
              "          [-3.4382e-02, -6.2208e-03, -2.4463e-02,  9.0948e-02,  4.1113e-02],\n",
              "          [-6.1112e-02,  5.2975e-02, -2.0110e-03,  3.2651e-02, -5.2369e-02],\n",
              "          [ 4.7376e-02, -3.2681e-02, -5.7571e-02,  1.6419e-02, -6.6171e-02],\n",
              "          [-6.6701e-02, -6.8945e-02,  3.0499e-02,  3.1829e-02,  7.4767e-02]],\n",
              "\n",
              "         [[ 8.2243e-02,  1.0065e-02,  9.2319e-02, -4.3468e-02,  4.6053e-02],\n",
              "          [-3.7506e-03, -4.7415e-02, -2.7104e-02, -9.1218e-02, -9.3813e-02],\n",
              "          [ 1.0306e-01, -8.6527e-02, -6.4951e-02, -5.5076e-02, -8.4500e-02],\n",
              "          [-4.4848e-02, -3.2836e-02,  7.7546e-02,  3.7543e-02, -3.3009e-02],\n",
              "          [ 3.4937e-02, -7.2479e-02,  7.6802e-02, -4.9778e-02,  9.8851e-02]],\n",
              "\n",
              "         [[ 1.1144e-02, -3.8709e-02, -8.2869e-02,  3.4470e-02, -5.9122e-03],\n",
              "          [ 7.2039e-02, -7.6249e-02,  6.9978e-02, -4.9853e-02,  2.9300e-02],\n",
              "          [ 4.0691e-02,  1.0336e-01, -2.1395e-02,  8.7452e-02,  8.9864e-02],\n",
              "          [-3.4572e-02, -9.5470e-02,  7.2884e-02,  6.4404e-02, -7.5328e-02],\n",
              "          [ 9.5842e-02, -1.7658e-02,  6.0697e-02,  7.5653e-03,  6.7531e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5071e-02, -7.5267e-02, -6.5442e-02, -7.0752e-02,  5.4356e-02],\n",
              "          [-4.1974e-02,  4.1854e-02,  7.9870e-03,  8.1940e-02, -5.5997e-02],\n",
              "          [ 1.7097e-02,  6.6222e-02,  2.9779e-02,  8.7268e-02, -3.3103e-02],\n",
              "          [-1.0043e-01, -9.2748e-03, -1.1939e-02,  6.3424e-02, -4.6069e-02],\n",
              "          [-4.2215e-02,  2.0725e-02,  8.7352e-02,  7.6871e-02,  7.1368e-02]],\n",
              "\n",
              "         [[ 1.8825e-02,  4.7554e-02,  3.8387e-02,  4.0775e-02, -1.0710e-02],\n",
              "          [ 7.0494e-02,  1.3679e-02,  9.1178e-02,  8.6025e-02,  1.0433e-01],\n",
              "          [-7.4046e-02, -1.4537e-02,  2.8675e-02,  5.6227e-02,  3.1027e-02],\n",
              "          [-9.5317e-02, -7.3444e-02, -7.1802e-03,  7.1863e-02,  4.9074e-02],\n",
              "          [-7.6059e-02, -9.6417e-02, -1.1816e-02,  9.7522e-02, -1.0353e-01]],\n",
              "\n",
              "         [[ 3.1916e-02, -5.2613e-02, -3.9748e-02, -3.1916e-02,  2.5619e-02],\n",
              "          [-9.0411e-02,  6.9345e-02, -1.5438e-03, -7.2275e-02,  4.9689e-02],\n",
              "          [ 6.2295e-02,  8.0108e-02, -2.6291e-02, -3.0119e-02,  7.8127e-02],\n",
              "          [ 2.5488e-02,  9.6542e-02, -5.7671e-02, -9.5750e-02,  5.8890e-02],\n",
              "          [-8.6706e-02, -8.0200e-02, -1.0078e-01, -3.6460e-02,  2.9198e-02]],\n",
              "\n",
              "         [[ 1.1225e-03,  9.5864e-02, -2.2103e-02,  7.3053e-02,  2.3240e-02],\n",
              "          [-7.0643e-02,  3.7649e-02,  8.7221e-02,  4.8005e-02,  9.8971e-02],\n",
              "          [ 5.5884e-02, -1.5641e-02,  1.2196e-02, -3.2393e-02,  5.4382e-02],\n",
              "          [ 8.2907e-02, -7.4190e-02, -9.4422e-02, -7.7318e-02, -5.8518e-02],\n",
              "          [ 3.5687e-02, -9.0090e-02, -1.1382e-02, -1.3215e-02, -7.9753e-03]],\n",
              "\n",
              "         [[-4.2038e-02, -7.7767e-02, -6.3475e-02, -6.9457e-02, -8.5586e-02],\n",
              "          [ 2.5902e-02, -1.0057e-01,  4.3891e-03,  4.2846e-02,  3.1837e-02],\n",
              "          [-6.6931e-02, -8.6553e-02,  1.0011e-01,  7.3945e-02,  9.3573e-03],\n",
              "          [-2.8636e-02, -7.6152e-02,  1.5390e-02,  7.4072e-02, -1.8941e-02],\n",
              "          [ 1.0003e-01, -9.6295e-02, -2.2371e-03, -6.3196e-02,  6.6062e-02]],\n",
              "\n",
              "         [[ 5.7184e-02,  1.6298e-02, -7.9067e-03,  9.4929e-02, -9.9462e-02],\n",
              "          [-1.0013e-01, -2.6005e-02, -3.2899e-02, -5.1820e-02, -7.6895e-02],\n",
              "          [ 3.5577e-02, -2.5474e-02, -3.0255e-02,  1.9486e-02, -4.8915e-02],\n",
              "          [-4.9782e-02,  5.1274e-02, -9.9372e-02, -9.8677e-02,  5.3287e-03],\n",
              "          [ 5.7571e-02, -1.0114e-02, -6.2863e-02, -6.2600e-02,  2.1339e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.0219e-02,  4.9373e-02, -1.5290e-02, -2.9458e-02, -3.9344e-02],\n",
              "          [-5.8688e-02,  9.2221e-02, -5.0488e-02,  3.1095e-02,  2.3565e-03],\n",
              "          [ 2.1814e-02, -5.4210e-02,  1.5828e-02,  6.3502e-02,  8.2438e-02],\n",
              "          [ 9.0688e-02,  2.1577e-02, -2.7743e-02, -5.7215e-02, -4.1647e-02],\n",
              "          [-7.4678e-02,  3.8933e-03, -1.6814e-02, -6.7459e-02,  2.2162e-02]],\n",
              "\n",
              "         [[-6.7992e-03, -9.2470e-02, -1.7106e-03, -6.3614e-02, -1.5970e-02],\n",
              "          [-7.7426e-02,  4.5973e-02, -9.3117e-02, -8.6345e-02, -8.1986e-02],\n",
              "          [-7.3835e-02, -7.1166e-02, -6.8161e-02,  7.1609e-03, -4.3742e-02],\n",
              "          [-7.4242e-02,  5.7794e-03,  3.6374e-02, -5.8859e-03,  5.0753e-02],\n",
              "          [ 5.9766e-02, -6.2497e-02,  8.2644e-02, -8.6121e-02,  3.8955e-04]],\n",
              "\n",
              "         [[ 4.2245e-02, -6.7507e-02,  7.8253e-02, -6.0968e-03,  5.0891e-02],\n",
              "          [ 7.6902e-02, -6.9467e-02,  2.3571e-02, -5.4190e-02, -9.2797e-02],\n",
              "          [ 5.2010e-02,  9.9516e-02, -2.8882e-02, -4.8082e-02,  4.0255e-03],\n",
              "          [-2.1960e-02, -8.6345e-02, -5.3910e-02,  6.5779e-02,  9.6450e-02],\n",
              "          [-2.2899e-03,  9.3139e-02, -7.7963e-02,  9.9898e-02,  3.4947e-02]],\n",
              "\n",
              "         [[ 5.1952e-02,  9.6443e-02, -5.1122e-02,  6.9036e-02,  7.9039e-02],\n",
              "          [-3.7922e-02,  5.6932e-02,  5.7460e-02,  4.0910e-02,  5.4506e-02],\n",
              "          [-2.5658e-02,  7.9196e-02,  3.3348e-03, -7.7305e-02,  2.4356e-02],\n",
              "          [-2.7922e-02, -9.6685e-02, -7.9970e-02,  6.3564e-02, -4.2097e-02],\n",
              "          [-4.8798e-02,  8.5022e-02,  8.6154e-03, -6.2958e-02, -6.3625e-02]],\n",
              "\n",
              "         [[-4.9472e-02,  2.3119e-02,  3.9362e-02, -8.7546e-02,  6.5148e-02],\n",
              "          [ 1.8927e-02,  5.3553e-02, -4.0064e-02, -5.5428e-02, -8.6832e-02],\n",
              "          [-8.5845e-04, -5.6248e-02,  9.7321e-02, -1.4779e-02,  4.2952e-02],\n",
              "          [-3.1564e-02, -4.5718e-02,  7.3874e-02,  7.5818e-02,  8.7330e-02],\n",
              "          [-1.9523e-02,  5.6465e-02,  6.9700e-03,  1.5032e-02,  1.1012e-02]],\n",
              "\n",
              "         [[-1.0441e-01, -3.9385e-02,  7.4438e-02, -6.6742e-02,  9.0290e-02],\n",
              "          [-8.9729e-02,  8.5796e-02, -3.5947e-03,  8.2186e-02, -6.0137e-02],\n",
              "          [ 6.4752e-02,  4.1746e-02, -5.3112e-03, -7.7848e-02,  2.6465e-02],\n",
              "          [-7.2710e-02, -8.5283e-02,  9.9565e-03, -3.8558e-02,  3.9364e-02],\n",
              "          [ 2.8096e-02,  8.0915e-02,  7.4408e-02, -4.8459e-02,  8.4853e-02]]]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10 # to load dataset\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "X_train = np.transpose(X_train, (0, 3, 1, 2))\n",
        "X_test = np.transpose(X_test, (0, 3, 1, 2))"
      ],
      "metadata": {
        "id": "WTJkEr01lBv6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criterion = nn.CrossEntropyLoss()\n",
        "optimizer = FullBatchLBFGS(model.parameters(), lr=1., history_size=10, line_search='Wolfe', debug=True)\n",
        "\n",
        "# Forward pass\n",
        "opfun = lambda X: model.forward(torch.tensor(X).to(device))\n",
        "\n",
        "# Forward pass through the network given the input\n",
        "predsfun = lambda op: np.argmax(op.cpu().data.numpy(), 1)\n",
        "\n",
        "# Do the forward pass, then compute the accuracy\n",
        "accfun = lambda op, y: np.mean(np.equal(predsfun(op), y.squeeze())) * 100\n",
        "\n",
        "# Main training loop\n",
        "no_samples = X_train.shape[0]\n",
        "\n",
        "# compute initial gradient and objective\n",
        "grad, obj = get_grad(optimizer, X_train, y_train, opfun)\n",
        "\n"
      ],
      "metadata": {
        "id": "vgmG8WWQlBs4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for L-BFGS training\n",
        "max_iter = 200\n",
        "ghost_batch = 128\n",
        "\n",
        "\n",
        "# main loop\n",
        "for n_iter in range(max_iter):\n",
        "\n",
        "    # training mode\n",
        "    model.train()\n",
        "\n",
        "    # define closure for line search\n",
        "    def closure():\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_fn = torch.tensor(0, dtype=torch.float).to(device)\n",
        "\n",
        "        for subsmpl in np.array_split(np.arange(no_samples), max(int(no_samples / ghost_batch), 1)):\n",
        "\n",
        "            ops = opfun(X_train[subsmpl])\n",
        "\n",
        "            tgts = torch.from_numpy(y_train[subsmpl]).to(device).long().squeeze()\n",
        "\n",
        "            loss_fn += F.cross_entropy(ops, tgts) * (len(subsmpl) / no_samples)\n",
        "\n",
        "        return loss_fn\n",
        "\n",
        "    # perform line search step\n",
        "    options = {'closure': closure, 'current_loss': obj}\n",
        "    obj, grad, lr, _, _, _, _, _ = optimizer.step(options)\n",
        "\n",
        "    # compute statistics\n",
        "    model.eval()\n",
        "    train_loss, test_loss, test_acc = compute_stats(X_train, y_train, X_test, y_test, opfun, accfun,\n",
        "                                                    ghost_batch=128)\n",
        "\n",
        "    # print data\n",
        "    print('Iter:', n_iter + 1, 'lr:', lr, 'Training Loss:', train_loss, 'Test Loss:', test_loss,\n",
        "          'Test Accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2MDYGpaglBqv",
        "outputId": "5d6b821d-70e5-4ab5-f47c-6c1eecec71f6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 1 lr: 4.0 Training Loss: 2.297409815716743 Test Loss: 2.2972478403329837 Test Accuracy: 9.95\n",
            "Iter: 2 lr: 0.2 Training Loss: 2.294278284583091 Test Loss: 2.2938123137950894 Test Accuracy: 10.119999999999997\n",
            "Iter: 3 lr: 1.0 Training Loss: 2.2879178206825257 Test Loss: 2.287668154406547 Test Accuracy: 13.340000000000002\n",
            "Iter: 4 lr: 2.0 Training Loss: 2.2617658226919177 Test Loss: 2.2625082651138304 Test Accuracy: 14.440000000000003\n",
            "Iter: 5 lr: 0.2 Training Loss: 2.25482784380436 Test Loss: 2.25677495856285 Test Accuracy: 13.640000000000002\n",
            "Iter: 6 lr: 1.0 Training Loss: 2.232477621331215 Test Loss: 2.2384168288707738 Test Accuracy: 17.070000000000004\n",
            "Iter: 7 lr: 1.0 Training Loss: 2.209806303195953 Test Loss: 2.215066414952279 Test Accuracy: 17.18000000000001\n",
            "Iter: 8 lr: 1.0 Training Loss: 2.1970162607765196 Test Loss: 2.1995690737485893 Test Accuracy: 17.48\n",
            "Iter: 9 lr: 1.0 Training Loss: 2.180640261464119 Test Loss: 2.1839404413938523 Test Accuracy: 20.989999999999995\n",
            "Iter: 10 lr: 0.25779625406606504 Training Loss: 2.173837786264419 Test Loss: 2.1777341683149336 Test Accuracy: 22.340000000000014\n",
            "Iter: 11 lr: 0.3468754980408598 Training Loss: 2.169493480296134 Test Loss: 2.1733052197933196 Test Accuracy: 21.789999999999996\n",
            "Iter: 12 lr: 1.0 Training Loss: 2.165344908547401 Test Loss: 2.1688734076499943 Test Accuracy: 22.290000000000003\n",
            "Iter: 13 lr: 1.0 Training Loss: 2.148477595472336 Test Loss: 2.149507179450989 Test Accuracy: 21.890000000000008\n",
            "Iter: 14 lr: 1.0 Training Loss: 2.130198076543808 Test Loss: 2.1274019001722335 Test Accuracy: 22.110000000000007\n",
            "Iter: 15 lr: 1.0 Training Loss: 2.0908641401433945 Test Loss: 2.082829852890968 Test Accuracy: 23.91\n",
            "Iter: 16 lr: 1.0 Training Loss: 2.0904368098545074 Test Loss: 2.080662054300308 Test Accuracy: 24.330000000000002\n",
            "Iter: 17 lr: 1.0 Training Loss: 2.0733431491136556 Test Loss: 2.064599911189079 Test Accuracy: 24.19\n",
            "Iter: 18 lr: 1.0 Training Loss: 2.0672232568740845 Test Loss: 2.0577547008395194 Test Accuracy: 24.98\n",
            "Iter: 19 lr: 1.0 Training Loss: 2.0608995015907285 Test Loss: 2.0515746618032464 Test Accuracy: 25.379999999999992\n",
            "Iter: 20 lr: 1.0 Training Loss: 2.049744808914662 Test Loss: 2.040114964914322 Test Accuracy: 26.06\n",
            "Iter: 21 lr: 1.0 Training Loss: 2.0426114452123634 Test Loss: 2.032869021201133 Test Accuracy: 26.17\n",
            "Iter: 22 lr: 1.0 Training Loss: 2.029995271127224 Test Loss: 2.0189549143075944 Test Accuracy: 26.74\n",
            "Iter: 23 lr: 1.0 Training Loss: 2.025687268698216 Test Loss: 2.0137176609277723 Test Accuracy: 26.59\n",
            "Iter: 24 lr: 1.0 Training Loss: 2.0206599571299546 Test Loss: 2.0094260531544683 Test Accuracy: 27.03\n",
            "Iter: 25 lr: 1.0 Training Loss: 2.0178133328843115 Test Loss: 2.0067173427462577 Test Accuracy: 27.15\n",
            "Iter: 26 lr: 1.0 Training Loss: 2.012170023207665 Test Loss: 2.0010448858141894 Test Accuracy: 27.810000000000006\n",
            "Iter: 27 lr: 1.0 Training Loss: 2.006407937626838 Test Loss: 1.9944598915934555 Test Accuracy: 28.069999999999986\n",
            "Iter: 28 lr: 1.0 Training Loss: 1.9961913628888135 Test Loss: 1.982812138330936 Test Accuracy: 28.060000000000016\n",
            "Iter: 29 lr: 1.0 Training Loss: 1.988184236922264 Test Loss: 1.9742581140637399 Test Accuracy: 27.599999999999994\n",
            "Iter: 30 lr: 1.0 Training Loss: 1.9766586724042894 Test Loss: 1.9639145855069164 Test Accuracy: 28.23\n",
            "Iter: 31 lr: 1.0 Training Loss: 1.959464191803932 Test Loss: 1.945273257827759 Test Accuracy: 28.049999999999986\n",
            "Iter: 32 lr: 1.0 Training Loss: 1.9468896093869215 Test Loss: 1.933732408761978 Test Accuracy: 28.66\n",
            "Iter: 33 lr: 1.0 Training Loss: 1.937625843851566 Test Loss: 1.9245919481158256 Test Accuracy: 29.68000000000001\n",
            "Iter: 34 lr: 1.0 Training Loss: 1.9299793679404256 Test Loss: 1.9188140357136725 Test Accuracy: 30.209999999999997\n",
            "Iter: 35 lr: 1.0 Training Loss: 1.9275389474940294 Test Loss: 1.9161091535568238 Test Accuracy: 30.26\n",
            "Iter: 36 lr: 1.0 Training Loss: 1.9236272809624668 Test Loss: 1.9121112235546112 Test Accuracy: 29.969999999999995\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-4ebe764b0410>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# compute statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     train_loss, test_loss, test_acc = compute_stats(X_train, y_train, X_test, y_test, opfun, accfun,\n\u001b[0m\u001b[1;32m     36\u001b[0m                                                     ghost_batch=128)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mcompute_stats\u001b[0;34m(X_train, y_train, X_test, y_test, opfun, accfun, ghost_batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# define test set ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtestops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmpl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# accumulate weighted test loss and test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-55c49b5c931d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Forward pass through the network given the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-c53b75ca5bc0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lnq14e5JyMwc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}